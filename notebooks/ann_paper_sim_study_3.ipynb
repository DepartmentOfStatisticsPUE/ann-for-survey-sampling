{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ann-paper-sim-study-3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMvTUnb/3dIE71pjAr3gKLr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DepartmentOfStatisticsPUE/ann-for-survey-sampling/blob/main/notebooks/ann_paper_sim_study_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsAD8OMvezI5"
      },
      "source": [
        "!apt install libomp-dev\n",
        "!pip install faiss-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Br6Vs_0fa34",
        "outputId": "dd04d4fb-6468-4c48-aade-d0843875a262"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import pickle\n",
        "import faiss\n",
        "from scipy.spatial import KDTree\n",
        "from scipy.spatial.distance import euclidean\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "res = faiss.StandardGpuResources() "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF1eaae6rFUg"
      },
      "source": [
        "def kdtree_impute(tree, sample, data, y, x, eps = 0):\n",
        "  nns = tree.query(sample[:,x], k = 1, eps = eps)\n",
        "  res = np.mean(data[nns[1]][:, ys], axis = 0)\n",
        "  return res"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeEqjAOux9z2"
      },
      "source": [
        "## Simulation 3A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ImvPed5q8km"
      },
      "source": [
        "Simulation study taken from: Kim, J. K., & Wang, Z. (2018). Sampling Techniques for Big Data Analysis. International Statistical Review, 1, 1â€“15. https://doi.org/10.1111/insr.12290"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik4LdbVDfMY_",
        "outputId": "32c4b9ef-5dae-4ef7-f381-ed0679e09205"
      },
      "source": [
        "np.random.seed(123)\n",
        "N = 1000000\n",
        "x1 = np.random.normal(loc=1.0,scale=1.0,size=N)\n",
        "x2 = np.random.exponential(scale=1.0, size = N)\n",
        "epsilon = np.random.normal(size=N)\n",
        "\n",
        "### target variables\n",
        "y1 = 1 + x1 + x2 + epsilon\n",
        "y2 = 0.5*(x1 - 1.5)**2 + x2 + epsilon\n",
        "## propensity scores\n",
        "p1 = np.exp(x2) / (1 + np.exp(x2))\n",
        "p2 = np.exp(-0.5 + 0.5*(x2-2)**2) / (1 + np.exp(-0.5 + 0.5*(x2-2)**2))\n",
        "\n",
        "data = np.column_stack((x1,x2,y1,y2,p1,p2)).astype('float32')\n",
        "data[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.0856306 ,  0.5546646 ,  0.90054107,  1.2432839 ,  0.63521713,\n",
              "         0.632858  ],\n",
              "       [ 1.9973454 ,  1.1975824 ,  4.455222  ,  1.5815529 ,  0.7680944 ,\n",
              "         0.4556015 ],\n",
              "       [ 1.2829785 ,  0.84342945,  3.0256119 ,  0.76618266,  0.699187  ,\n",
              "         0.542107  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xtafAIGfqcI",
        "outputId": "7e277fdb-0dab-42bb-833e-6ca68095323a"
      },
      "source": [
        "R = 10\n",
        "xs = [0,1]\n",
        "ys = [2,3]\n",
        "ps = [4,5]\n",
        "\n",
        "results_faiss_500 = np.zeros(shape = (R, 2))\n",
        "results_faiss_1000 = np.zeros(shape = (R, 2))\n",
        "results_kdtree_500 = np.zeros(shape = (R, 2))\n",
        "results_kdtree_1000 = np.zeros(shape = (R, 2))\n",
        "\n",
        "for r in range(R):\n",
        "  print(r)\n",
        "  np.random.seed(r)\n",
        "  ## big data sample\n",
        "  big_p1 = np.random.binomial(n=1, p = p1, size = N)\n",
        "  big_p2 = np.random.binomial(n=1, p = p2, size = N)    \n",
        "  ## random samples\n",
        "  s500 = np.random.choice(a = data.shape[0], size = 500, replace = False)\n",
        "  s1000 = np.random.choice(a = data.shape[0], size = 1000, replace = False)\n",
        "  ## kdtree (exact)\n",
        "  kdtree = KDTree(data[big_p2==1][:, xs], leafsize = 100)\n",
        "  results_kdtree_500[r, :] = kdtree_impute(kdtree, data[s500], data[big_p2==1], ys, xs, eps = 100)\n",
        "  results_kdtree_1000[r, :] = kdtree_impute(kdtree, data[s1000], data[big_p2==1], ys, xs, eps = 100)\n",
        "  ## faiss\n",
        "  big_data = data[big_p2==1][:, xs].copy()\n",
        "  sam_data_500 = data[s500][:, xs].copy()\n",
        "  sam_data_1000 = data[s1000][:, xs].copy()\n",
        "  index_flat = faiss.IndexFlatL2(len(xs))\n",
        "  gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)\n",
        "  gpu_index_flat.add(big_data)\n",
        "  D_500, I_500 = gpu_index_flat.search(sam_data_500, k = 1) \n",
        "  D_1000, I_1000 = gpu_index_flat.search(sam_data_1000, k = 1) \n",
        "  ind_500 = [i[0] for i in I_500]\n",
        "  ind_1000 = [i[0] for i in I_1000]\n",
        "  results_faiss_500[r,:]=np.mean(data[big_p2==1][ind_500][:, ys], axis=0)\n",
        "  results_faiss_1000[r,:]=np.mean(data[big_p2==1][ind_1000][:, ys], axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhEJCYsWlZNW",
        "outputId": "876ea339-7caf-4dda-e9e5-144cdadbbfd3"
      },
      "source": [
        "expected = np.stack(\n",
        "    [np.mean(results_kdtree_500, axis=0),\n",
        "     np.mean(results_faiss_500, axis=0),\n",
        "     np.mean(results_kdtree_1000, axis=0),\n",
        "     np.mean(results_faiss_1000, axis=0)\n",
        "     ]\n",
        ") \n",
        "\n",
        "stderrs =  np.stack(\n",
        "    [np.std(results_kdtree_500, axis=0),\n",
        "     np.std(results_faiss_500, axis=0),\n",
        "     np.std(results_kdtree_1000, axis=0),\n",
        "     np.std(results_faiss_1000, axis=0)\n",
        "     ]\n",
        ")\n",
        "\n",
        "bias = expected - np.mean(data[:,ys], axis=0)\n",
        "mse = bias**2 + stderrs**2\n",
        "\n",
        "print(\"===== bias =====\")\n",
        "print(bias)\n",
        "print(\"===== se =====\")\n",
        "print(stderrs)\n",
        "print(\"===== mse =====\")\n",
        "print(mse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== bias =====\n",
            "[[-0.00685911 -0.02907437]\n",
            " [-0.00759137 -0.02993623]\n",
            " [ 0.0285023   0.01061232]\n",
            " [ 0.03065183  0.01280404]]\n",
            "===== se =====\n",
            "[[0.05752631 0.10151303]\n",
            " [0.05390689 0.0999129 ]\n",
            " [0.04877032 0.03980684]\n",
            " [0.05182396 0.04317026]]\n",
            "===== mse =====\n",
            "[[0.00335632 0.01115022]\n",
            " [0.00296358 0.01087877]\n",
            " [0.00319093 0.00169721]\n",
            " [0.00362526 0.00202762]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czxaj3oawu6m"
      },
      "source": [
        "## save results\n",
        "results = {\n",
        "    \"results_kdtree_500\" : pd.DataFrame(results_kdtree_500),\n",
        "    \"results_faiss_500\" : pd.DataFrame(results_faiss_500),\n",
        "    \"results_kdtree_1000\": pd.DataFrame(results_kdtree_1000),\n",
        "    \"results_faiss_1000\": pd.DataFrame(results_faiss_1000),\n",
        "           }\n",
        "\n",
        "f = open(\"kdtree_faiss_500_1000k.pkl\",\"wb\")\n",
        "pickle.dump(results,f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQNLdp9IyGE6"
      },
      "source": [
        "## Simulation 3B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGA2ywP5reji"
      },
      "source": [
        "Modified case from: Yang, S., & Kim, J. K. (2019). Nearest neighbour imputation for general parameter estimation in survey sampling. In The Econometrics of Complex Survey Data: Theory and Applications (Vol. 39, pp. 209â€“234)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93ciOzNyGAEY"
      },
      "source": [
        "def kdtree_impute2(tree, data_obs, data_not, y, x, N, eps = 0):\n",
        "  nns = tree.query(data_not[:,xs], k = 1, eps = eps)\n",
        "  res = (np.sum(data_obs[nns[1]][:, ys], axis = 0) + np.sum(data_obs[:, ys], axis = 0)) / N\n",
        "  return res"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krpxc0VqDpgK",
        "outputId": "7d888e83-fd80-4806-9f98-77d0f2ef5033"
      },
      "source": [
        "np.random.seed(123)\n",
        "N = 50000\n",
        "x1 = np.random.uniform(size = N)\n",
        "x2 = np.random.uniform(size = N)\n",
        "x3 = np.random.uniform(size = N)\n",
        "x4 = np.random.normal(size = N)\n",
        "x5 = np.random.normal(size = N)\n",
        "x6 = np.random.normal(size = N)\n",
        "epsilon = np.random.normal(size=N)\n",
        "\n",
        "### target variables\n",
        "y1 = -1 + x1 + x2 + epsilon\n",
        "y2 = -1.5 + x1 + x2 + x3 + x4 + epsilon\n",
        "y3 = -1.5 + x1 + x2 + x3 + x4 + x5 + x6 + epsilon\n",
        "y4 = -1 + x1 + x2 + x1**2 + x2**2 -2/3 + epsilon\n",
        "y5 = -1 + x1 + x2 + x3 + x4 + x1**2 + x2**2 -2/3 + epsilon\n",
        "y6 = -1 + x1 + x2 + x3 + x4 + x5 + x6 + x1**2 + x2**2 -2/3 + epsilon\n",
        "\n",
        "## propensity scores\n",
        "p1 = np.exp(1 + x1 + x2 + x3 + x4 + x5 + x6) / (1 + np.exp(1 + x1 + x2 + x3 + x4 + x5 + x6))\n",
        "p2 = np.exp(1 + x1 + x2) / (1 + np.exp(1 + x1 + x2))\n",
        "\n",
        "data = np.column_stack((x1,x2,x3,x4,x5,x6,y1,y2,y3,y4,y5,y6)).astype('float32')\n",
        "data[:3]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.6964692 ,  0.36086547,  0.20932843,  0.47665665,  0.80429375,\n",
              "        -0.9894137 ,  0.42543107,  0.61141616,  0.42629617,  0.3740576 ,\n",
              "         1.0600427 ,  0.87492275],\n",
              "       [ 0.28613934,  0.22535679,  0.2937351 ,  0.6701647 ,  1.2931948 ,\n",
              "         1.033963  ,  0.25331086,  0.71721065,  3.0443685 , -0.2806944 ,\n",
              "         0.6832054 ,  3.010363  ],\n",
              "       [ 0.22685145,  0.50813043,  0.05571789,  0.5033514 ,  1.5591047 ,\n",
              "         0.13504769,  0.36729714,  0.42636642,  2.1205187 ,  0.0102886 ,\n",
              "         0.5693579 ,  2.2635102 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQWApDb3EptG"
      },
      "source": [
        "R = 500\n",
        "xs = [0,1,2,3,4,5]\n",
        "ys = [6,7,8,9,10,11]\n",
        "\n",
        "results_faiss = np.zeros(shape = (R, 6))\n",
        "results_kdtree = np.zeros(shape = (R, 6))\n",
        "results_pmm = np.zeros(shape = (R, 6))\n",
        "results_identical = np.zeros(shape = (R,1))\n",
        "\n",
        "for r in range(R):\n",
        "  print(r)\n",
        "  np.random.seed(r)\n",
        "  ## big data sample\n",
        "  big_p1 = np.random.binomial(n=1, p = p1, size = N)\n",
        "  ## data\n",
        "  data_obs = data[big_p1 == 1].copy()\n",
        "  data_not = data[big_p1 != 1].copy()\n",
        "  ## running\n",
        "  X_obs = data_obs[:, xs]\n",
        "  X_obs = sm.add_constant(X_obs)\n",
        "  y_obs = data_obs[:, ys[5]]\n",
        "  ols_y = sm.OLS(y_obs, X_obs).fit()\n",
        "  X_not = data_not[:, xs]\n",
        "  X_not = sm.add_constant(X_not)\n",
        "  y_not = np.dot(X_not, ols_y.params)\n",
        "  ## nearest nn\n",
        "  neigh = NearestNeighbors(n_neighbors=1, algorithm='kd_tree').fit(ols_y.fittedvalues.reshape(-1, 1))\n",
        "  inds = neigh.kneighbors(y_not.reshape(-1,1), return_distance=False)\n",
        "  results_pmm[r, 5] = (np.sum(y_obs) + np.sum(y_obs[inds]))/N\n",
        "  ## faiss\n",
        "  data_obs_faiss = ols_y.fittedvalues.copy().reshape(-1, 1).astype('float32')\n",
        "  data_not_faiss = y_not.copy().reshape(-1, 1).astype('float32')\n",
        "  index_flat = faiss.IndexFlatL2(1)\n",
        "  gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)\n",
        "  gpu_index_flat.add(data_obs_faiss)\n",
        "  faiss_dists, faiss_inds = gpu_index_flat.search(data_not_faiss, k = 1) \n",
        "  results_faiss[r, 5] = (np.sum(y_obs) + np.sum(y_obs[faiss_inds]))/N\n",
        "  ## identical\n",
        "  results_identical[r, 0] = sum(inds.flatten() == faiss_inds.flatten()) / len(data_not_faiss)\n",
        "  ## kdtree\n",
        "  #kdtree = KDTree(data_obs_faiss, leafsize = 10)\n",
        "  #dd, ii = kdtree.query(data_not_faiss, k=1)\n",
        "  #results_kdtree[r,:]= (np.sum(data_obs[ii][:, ys], axis=0) + np.sum(data_obs[:, ys], axis=0)) / N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHg_WgtWIVKU",
        "outputId": "81257fc5-7dbd-49c3-dd22-0320bd572fed"
      },
      "source": [
        "expected = np.stack(\n",
        "    [np.mean(results_kdtree, axis=0),\n",
        "     np.mean(results_faiss, axis=0)\n",
        "     ]\n",
        ") \n",
        "\n",
        "stderrs =  np.stack(\n",
        "    [np.std(results_kdtree, axis=0),\n",
        "     np.std(results_faiss, axis=0)\n",
        "     ]\n",
        ")\n",
        "\n",
        "bias = expected - np.mean(data[:,ys], axis=0)\n",
        "mse = bias**2 + stderrs**2\n",
        "\n",
        "print(\"===== bias =====\")\n",
        "print(bias[:,5])\n",
        "print(\"===== se =====\")\n",
        "print(stderrs[:, 5])\n",
        "print(\"===== mse =====\")\n",
        "print(np.round(mse,4))\n",
        "print(np.round(expected,4))\n",
        "print(\"===== pmm =====\")\n",
        "print(np.mean(results_pmm[:, 5])-np.mean(data[:,ys[5]], axis=0))\n",
        "print(np.std(results_pmm[:, 5]))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== bias =====\n",
            "[-0.51053309  0.00152759]\n",
            "===== se =====\n",
            "[0.        0.0037306]\n",
            "===== mse =====\n",
            "[[0.000e+00 1.000e-04 1.000e-04 0.000e+00 2.577e-01 2.606e-01]\n",
            " [0.000e+00 1.000e-04 1.000e-04 0.000e+00 2.577e-01 0.000e+00]]\n",
            "[[0.     0.     0.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.5121]]\n",
            "===== pmm =====\n",
            "0.0014384213751220676\n",
            "0.003692713071889185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9Fj0rKcTsoR",
        "outputId": "6164af2e-5659-49b4-a38b-92a201f2353b"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6216522566575691"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g84x0QZyG2l"
      },
      "source": [
        "## Simulation 3C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvq0MP_BsuZI"
      },
      "source": [
        "Study from Yang, S., & Kim, J. K. (2020). Doubly robust inference when combining probability and non-probability samples with high dimensional. Journal of the Royal Statistical Society. Series B: Statistical Methodology, 82(2), 445â€“465. https://doi.org/10.1111/rssb.12354\n",
        "\n",
        "R code (source: https://github.com/shuyang1987/IntegrativeFPM)\n",
        "\n",
        "```r\n",
        "set.seed(1234)\n",
        "## population size\n",
        "N <- 10000\n",
        "## x is a p-dimensional covariate\n",
        "p <- 50\n",
        "x <- matrix( rnorm(N*p,0,1),N,p)\n",
        "## y is a continuous outcome \n",
        "beta0 <- c(1,1,1,1,1,rep(0,p-4))\n",
        "y <- cbind(1,x)%*%beta0 + rnorm(N,0,1)\n",
        "true <- mean(y)\n",
        "## y2 is a binary outcome\n",
        "ly2 <- (cbind(1,x)%*%beta0)\n",
        "ply <- exp(ly2)/(1+exp(ly2))\n",
        "y2 <- rbinom(N,1,ply)\n",
        "true2 <- mean(y2)\n",
        "## A.set is a prob sample: SRS\n",
        "## sampling probability into A is known when estimation\n",
        "nAexp <- 1000\n",
        "probA <- rep(nAexp/N,N)\n",
        "A.index <- rbinom(N,size = 1,prob = probA)\n",
        "A.loc <- which(A.index == 1)\n",
        "nA <- sum(A.index == 1)\n",
        "sw.A <- 1/probA[A.loc]\n",
        "x.A <- x[A.loc,]\n",
        "y.A <- rep(NA,nA) # y is not observed in Sample A\n",
        "y2.A <- rep(NA,nA)\n",
        "## B.set is a nonprob sample\n",
        "## sampling probability into B is unknown when estimation\n",
        "nBexp <- 2000\n",
        "alpha0 <- c(-2,1,1,1,1,rep(0,p-4))\n",
        "probB <- (1+exp(-cbind(1,x)%*%alpha0))^(-1) \n",
        "B.index <- rbinom(N,size = 1,prob = probB)\n",
        "B.loc <- which(B.index == 1)\n",
        "nB <- sum(B.index)\n",
        "x.B <- x[B.loc,]\n",
        "y.B <- y[B.loc]\n",
        "y2.B <- y2[B.loc]\n",
        "## combined dataset\n",
        "y.AB <- c(y.A,y.B)\n",
        "y2.AB <- c(y2.A,y2.B)\n",
        "x.AB <- rbind(x.A,x.B)\n",
        "deltaB <- c(rep(0,nA),rep(1,nB))\n",
        "sw <- c(sw.A,rep(1,nB))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERf_wTZ3reNq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}