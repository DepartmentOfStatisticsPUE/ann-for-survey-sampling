{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ann-paper-sim-study-3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOVaGCjMwhvtkV4JMNbR85O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DepartmentOfStatisticsPUE/ann-for-survey-sampling/blob/main/notebooks/ann_paper_sim_study_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MObvIeDFjd7-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGYvVd_KE88x",
        "outputId": "2430ce2a-6159-46e2-869c-3cc87c69bd4c"
      },
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!conda install -c conda-forge cupy cudatoolkit=10.0\n",
        "!apt install libomp-dev\n",
        "!pip install faiss-gpu"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "üì¶ Installing...\n",
            "üìå Adjusting configuration...\n",
            "ü©π Patching environment...\n",
            "‚è≤ Done in 0:00:36\n",
            "üîÅ Restarting kernel...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Br6Vs_0fa34"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "## https://docs.cupy.dev/en/stable/tutorial/basic.html \n",
        "## https://docs.cupy.dev/en/stable/install.html#installing-cupy-from-conda-forge\n",
        "import cupy as cp \n",
        "import cupyx as cpx\n",
        "import statsmodels.api as sm\n",
        "import pickle\n",
        "import faiss\n",
        "import time\n",
        "from scipy.spatial import KDTree\n",
        "from scipy.spatial.distance import euclidean\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "res = faiss.StandardGpuResources() "
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF1eaae6rFUg"
      },
      "source": [
        "def kdtree_impute(tree, sample, data, y, x, eps = 0):\n",
        "  nns = tree.query(sample[:,x], k = 1, eps = eps)\n",
        "  res = np.mean(data[nns[1]][:, ys], axis = 0)\n",
        "  return res"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeEqjAOux9z2"
      },
      "source": [
        "## Simulation 3A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ImvPed5q8km"
      },
      "source": [
        "Simulation study taken from: Kim, J. K., & Wang, Z. (2018). Sampling Techniques for Big Data Analysis. International Statistical Review, 1, 1‚Äì15. https://doi.org/10.1111/insr.12290"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik4LdbVDfMY_",
        "outputId": "c69ddc63-e867-4dc5-cadf-dbcb166861be"
      },
      "source": [
        "#t = time.time()\n",
        "np.random.seed(123) \n",
        "N = 1000000\n",
        "x1 = np.random.normal(loc=1.0,scale=1.0,size=N)\n",
        "x2 = np.random.exponential(scale=1.0, size = N)\n",
        "epsilon = np.random.normal(size=N)\n",
        "\n",
        "### target variables\n",
        "y1 = 1 + x1 + x2 + epsilon\n",
        "y2 = 0.5*(x1 - 1.5)**2 + x2 + epsilon\n",
        "## propensity scores\n",
        "p1 = np.exp(x2) / (1 + np.exp(x2))\n",
        "p2 = np.exp(-0.5 + 0.5*(x2-2)**2) / (1 + np.exp(-0.5 + 0.5*(x2-2)**2))\n",
        "\n",
        "data = np.column_stack((x1,x2,y1,y2,p1,p2)).astype('float32')\n",
        "#time.time() - t\n",
        "data[:3]"
      ],
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.0856306 ,  0.5546646 ,  0.90054107,  1.2432839 ,  0.63521713,\n",
              "         0.632858  ],\n",
              "       [ 1.9973454 ,  1.1975824 ,  4.455222  ,  1.5815529 ,  0.7680944 ,\n",
              "         0.4556015 ],\n",
              "       [ 1.2829785 ,  0.84342945,  3.0256119 ,  0.76618266,  0.699187  ,\n",
              "         0.542107  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xtafAIGfqcI",
        "outputId": "06e1a841-f16f-4fb1-f62c-13acba2d5198"
      },
      "source": [
        "R = 10\n",
        "xs = [0,1]\n",
        "ys = [2,3]\n",
        "ps = [4,5]\n",
        "\n",
        "results_faiss_500 = np.zeros(shape = (R, 2))\n",
        "results_faiss_1000 = np.zeros(shape = (R, 2))\n",
        "results_kdtree_500 = np.zeros(shape = (R, 2))\n",
        "results_kdtree_1000 = np.zeros(shape = (R, 2))\n",
        "\n",
        "for r in range(R):\n",
        "  print(r)\n",
        "  np.random.seed(r)\n",
        "  ## big data sample\n",
        "  big_p1 = np.random.binomial(n=1, p = p1, size = N)\n",
        "  big_p2 = np.random.binomial(n=1, p = p2, size = N)    \n",
        "  ## random samples\n",
        "  s500 = np.random.choice(a = data.shape[0], size = 500, replace = False)\n",
        "  s1000 = np.random.choice(a = data.shape[0], size = 1000, replace = False)\n",
        "  ## kdtree (exact)\n",
        "  kdtree = KDTree(data[big_p2==1][:, xs], leafsize = 100)\n",
        "  results_kdtree_500[r, :] = kdtree_impute(kdtree, data[s500], data[big_p2==1], ys, xs, eps = 0)\n",
        "  results_kdtree_1000[r, :] = kdtree_impute(kdtree, data[s1000], data[big_p2==1], ys, xs, eps = 0)\n",
        "  ## faiss\n",
        "  big_data = data[big_p2==1][:, xs].copy()\n",
        "  sam_data_500 = data[s500][:, xs].copy()\n",
        "  sam_data_1000 = data[s1000][:, xs].copy()\n",
        "  index_flat = faiss.IndexFlatL2(len(xs))\n",
        "  gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)\n",
        "  gpu_index_flat.add(big_data)\n",
        "  D_500, I_500 = gpu_index_flat.search(sam_data_500, k = 1) \n",
        "  D_1000, I_1000 = gpu_index_flat.search(sam_data_1000, k = 1) \n",
        "  results_faiss_500[r,:]=np.mean(data[big_p2==1][I_500.flatten()][:, ys], axis=0)\n",
        "  results_faiss_1000[r,:]=np.mean(data[big_p2==1][I_1000.flatten()][:, ys], axis=0)"
      ],
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhEJCYsWlZNW",
        "outputId": "3a319040-3871-42ac-a4bd-d33c0230524d"
      },
      "source": [
        "expected = np.stack(\n",
        "    [np.mean(results_kdtree_500, axis=0),\n",
        "     np.mean(results_faiss_500, axis=0),\n",
        "     np.mean(results_kdtree_1000, axis=0),\n",
        "     np.mean(results_faiss_1000, axis=0)\n",
        "     ]\n",
        ") \n",
        "\n",
        "stderrs =  np.stack(\n",
        "    [np.std(results_kdtree_500, axis=0),\n",
        "     np.std(results_faiss_500, axis=0),\n",
        "     np.std(results_kdtree_1000, axis=0),\n",
        "     np.std(results_faiss_1000, axis=0)\n",
        "     ]\n",
        ")\n",
        "\n",
        "bias = expected - np.mean(data[:,ys], axis=0)\n",
        "mse = bias**2 + stderrs**2\n",
        "\n",
        "print(\"===== bias =====\")\n",
        "print(bias)\n",
        "print(\"===== se =====\")\n",
        "print(stderrs)\n",
        "print(\"===== mse =====\")\n",
        "print(mse)"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== bias =====\n",
            "[[-0.0095598  -0.03190564]\n",
            " [-0.0071245  -0.02946934]\n",
            " [ 0.03106031  0.01321316]\n",
            " [ 0.03051281  0.01266494]]\n",
            "===== se =====\n",
            "[[0.0561105  0.10153849]\n",
            " [0.05479202 0.09999034]\n",
            " [0.05094645 0.04202207]\n",
            " [0.05184517 0.04317867]]\n",
            "===== mse =====\n",
            "[[0.00323978 0.01132803]\n",
            " [0.00305292 0.01086651]\n",
            " [0.00356028 0.00194044]\n",
            " [0.00361895 0.0020248 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czxaj3oawu6m"
      },
      "source": [
        "## save results\n",
        "results = {\n",
        "    \"results_kdtree_500\" : pd.DataFrame(results_kdtree_500),\n",
        "    \"results_faiss_500\" : pd.DataFrame(results_faiss_500),\n",
        "    \"results_kdtree_1000\": pd.DataFrame(results_kdtree_1000),\n",
        "    \"results_faiss_1000\": pd.DataFrame(results_faiss_1000),\n",
        "           }\n",
        "\n",
        "f = open(\"kdtree_faiss_500_1000k.pkl\",\"wb\")\n",
        "pickle.dump(results,f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQNLdp9IyGE6"
      },
      "source": [
        "## Simulation 3B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGA2ywP5reji"
      },
      "source": [
        "Modified case from: Yang, S., & Kim, J. K. (2019). Nearest neighbour imputation for general parameter estimation in survey sampling. In The Econometrics of Complex Survey Data: Theory and Applications (Vol. 39, pp. 209‚Äì234)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93ciOzNyGAEY"
      },
      "source": [
        "def kdtree_impute2(tree, data_obs, data_not, y, x, N, eps = 0):\n",
        "  nns = tree.query(data_not[:,xs], k = 1, eps = eps)\n",
        "  res = (np.sum(data_obs[nns[1]][:, ys], axis = 0) + np.sum(data_obs[:, ys], axis = 0)) / N\n",
        "  return res"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krpxc0VqDpgK",
        "outputId": "360bc934-107c-417f-973d-b0fe4d90f1a2"
      },
      "source": [
        "np.random.seed(123)\n",
        "N = 500000\n",
        "x1 = np.random.uniform(size = N)\n",
        "x2 = np.random.uniform(size = N)\n",
        "x3 = np.random.uniform(size = N)\n",
        "x4 = np.random.normal(size = N)\n",
        "x5 = np.random.normal(size = N)\n",
        "x6 = np.random.normal(size = N)\n",
        "epsilon = np.random.normal(size=N)\n",
        "\n",
        "### target variables\n",
        "y1 = -1 + x1 + x2 + epsilon\n",
        "y2 = -1.5 + x1 + x2 + x3 + x4 + epsilon\n",
        "y3 = -1.5 + x1 + x2 + x3 + x4 + x5 + x6 + epsilon\n",
        "y4 = -1 + x1 + x2 + x1**2 + x2**2 -2/3 + epsilon\n",
        "y5 = -1 + x1 + x2 + x3 + x4 + x1**2 + x2**2 -2/3 + epsilon\n",
        "y6 = -1 + x1 + x2 + x3 + x4 + x5 + x6 + x1**2 + x2**2 -2/3 + epsilon\n",
        "\n",
        "## propensity scores\n",
        "p1 = np.exp(1 + x1 + x2 + x3 + x4 + x5 + x6) / (1 + np.exp(1 + x1 + x2 + x3 + x4 + x5 + x6))\n",
        "p2 = np.exp(1 + x1 + x2) / (1 + np.exp(1 + x1 + x2))\n",
        "\n",
        "data = np.column_stack((x1,x2,x3,x4,x5,x6,y1,y2,y3,y4,y5,y6)).astype('float32')\n",
        "data[:3]"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.6964692 ,  0.39244577,  0.772698  ,  0.06619908,  1.181968  ,\n",
              "         0.33423862,  0.454862  ,  0.79375905,  2.3099656 ,  0.42727834,\n",
              "         1.2661754 ,  2.782382  ],\n",
              "       [ 0.28613934,  0.46933195,  0.46711504,  0.33278647,  0.22954535,\n",
              "         0.11521499,  0.9884662 ,  1.2883677 ,  1.633128  ,  0.62394774,\n",
              "         1.4238492 ,  1.7686096 ],\n",
              "       [ 0.22685145,  0.62351155,  0.01994883, -1.044568  ,  0.11454313,\n",
              "        -0.31842756, -2.2750313 , -3.7996504 , -4.003535  , -2.5014696 ,\n",
              "        -3.5260887 , -3.7299733 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQWApDb3EptG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25dada9b-3c14-4fa6-9821-1787ff16d9fd"
      },
      "source": [
        "R = 100\n",
        "xs = [0,1,2,3,4,5]\n",
        "ys = [6,7,8,9,10,11]\n",
        "\n",
        "results_faiss = np.zeros(shape = (R, 6))\n",
        "results_kdtree = np.zeros(shape = (R, 6))\n",
        "results_pmm = np.zeros(shape = (R, 6))\n",
        "results_identical = np.zeros(shape = (R,1))\n",
        "timing_faiss = 0\n",
        "timing_kdtree = 0\n",
        "\n",
        "for r in range(R):\n",
        "  print(r)\n",
        "  np.random.seed(r)\n",
        "  ## big data sample\n",
        "  big_p1 = np.random.binomial(n=1, p = p1, size = N)\n",
        "  ## data\n",
        "  data_obs = data[big_p1 == 1]\n",
        "  data_not = data[big_p1 != 1]\n",
        "  ## running\n",
        "  X_obs = data_obs[:, xs]\n",
        "  X_obs = sm.add_constant(X_obs)\n",
        "  y_obs = data_obs[:, ys[5]]\n",
        "  ols_y = sm.OLS(y_obs, X_obs).fit()\n",
        "  X_not = data_not[:, xs]\n",
        "  X_not = sm.add_constant(X_not)\n",
        "  y_not = np.dot(X_not, ols_y.params)\n",
        "  \n",
        "  ## nearest nn\n",
        "  t = time.time()\n",
        "  neigh = NearestNeighbors(n_neighbors=1, algorithm='kd_tree').fit(ols_y.fittedvalues.reshape(-1, 1))\n",
        "  dists, inds = neigh.kneighbors(y_not.reshape(-1,1), return_distance=True)\n",
        "  timing_kdtree += time.time() - t\n",
        "  results_pmm[r, 5] = (np.sum(y_obs) + np.sum(y_obs[inds]))/N\n",
        "\n",
        "  #neigh = NearestNeighbors(n_neighbors=5, algorithm='kd_tree').fit(ols_y.fittedvalues.reshape(-1, 1))\n",
        "  #inds = neigh.kneighbors(y_not.reshape(-1,1), return_distance=False)\n",
        "  #results_pmm[r, 5] = (np.sum(y_obs) + np.sum(np.mean(y_obs[inds], axis=1))) /N\n",
        "  ## faiss\n",
        "  data_obs_faiss = ols_y.fittedvalues.copy().reshape(-1, 1).astype('float32')\n",
        "  data_not_faiss = y_not.copy().reshape(-1, 1).astype('float32')\n",
        "  \n",
        "  t = time.time()\n",
        "  index_flat = faiss.IndexFlatL2(1)\n",
        "  index_flat = faiss.IndexIVFFlat(index_flat, 1, 1000) ## number of cells = 1000\n",
        "  gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)\n",
        "  gpu_index_flat.train(data_obs_faiss)\n",
        "  gpu_index_flat.add(data_obs_faiss)\n",
        "  faiss_dists, faiss_inds = gpu_index_flat.search(data_not_faiss, k = 1)\n",
        "  timing_faiss += time.time() - t\n",
        "\n",
        "  results_faiss[r, 5] = (np.sum(y_obs) + np.sum(y_obs[faiss_inds]))/N\n",
        "  #faiss_dists, faiss_inds = gpu_index_flat.search(data_not_faiss, k = 5) \n",
        "  #results_faiss[r, 5] =  (np.sum(y_obs) + np.sum(np.mean(y_obs[faiss_inds], axis = 1)))/N\n",
        "  ## identical\n",
        "  results_identical[r, 0] = sum(inds.flatten() == faiss_inds.flatten()) / len(data_not_faiss)\n",
        "  ## kdtree\n",
        "  #kdtree = KDTree(data_obs_faiss, leafsize = 10)\n",
        "  #dd, ii = kdtree.query(data_not_faiss, k=1)\n",
        "  #results_kdtree[r,:]= (np.sum(data_obs[ii][:, ys], axis=0) + np.sum(data_obs[:, ys], axis=0)) / N"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y2viY_WE9Df",
        "outputId": "925eae3a-25ad-40ae-f300-3be04edfd9a9"
      },
      "source": [
        "timing_faiss, timing_kdtree"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31.84601902961731, 143.03165912628174)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKZ0pW0_No29",
        "outputId": "7e02ccf5-87a4-474e-a663-82916ba800c3"
      },
      "source": [
        "np.mean(results_identical)"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9964409603961438"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 250
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHg_WgtWIVKU",
        "outputId": "d9383eed-f019-4fe2-ccb0-b77c20845c58"
      },
      "source": [
        "expected = np.stack(\n",
        "    [np.mean(results_kdtree, axis=0),\n",
        "     np.mean(results_faiss, axis=0)\n",
        "     ]\n",
        ") \n",
        "\n",
        "stderrs =  np.stack(\n",
        "    [np.std(results_kdtree, axis=0),\n",
        "     np.std(results_faiss, axis=0)\n",
        "     ]\n",
        ")\n",
        "\n",
        "bias = expected - np.mean(data[:,ys], axis=0)\n",
        "mse = bias**2 + stderrs**2\n",
        "\n",
        "print(\"===== bias =====\")\n",
        "print(bias[:,5])\n",
        "print(\"===== se =====\")\n",
        "print(stderrs[:, 5])\n",
        "print(\"===== mse =====\")\n",
        "print(np.round(mse,4))\n",
        "print(np.round(expected,4))\n",
        "print(\"===== pmm =====\")\n",
        "print(np.mean(results_pmm[:, 5])-np.mean(data[:,ys[5]], axis=0))\n",
        "print(np.std(results_pmm[:, 5]))"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== bias =====\n",
            "[-0.49780464  0.00197833]\n",
            "===== se =====\n",
            "[0.         0.00267703]\n",
            "===== mse =====\n",
            "[[0.     0.     0.     0.     0.2499 0.2478]\n",
            " [0.     0.     0.     0.     0.2499 0.    ]]\n",
            "[[0.     0.     0.     0.     0.     0.    ]\n",
            " [0.     0.     0.     0.     0.     0.4998]]\n",
            "===== pmm =====\n",
            "0.002013671557617114\n",
            "0.0026393419641810977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnuQTu_t7R9d",
        "outputId": "8e66ae16-6d82-46dc-8a1a-ca98a8bfaafc"
      },
      "source": [
        "t = time.time()\n",
        "print(np.mean(dists))\n",
        "print(np.mean(faiss_dists))\n",
        "\n",
        "compare_dists = pd.DataFrame(data = np.column_stack((dists.flatten(), faiss_dists.flatten())),\n",
        "                             columns = [\"kdtree\",\"faiss\"])\n",
        "compare_dists.corr(method = \"pearson\")\n",
        "#compare_dists.plot.scatter(x = \"kdtree\", y = \"faiss\")\n",
        "timing_faiss =0\n",
        "timing_faiss += 1\n",
        "timing_faiss"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0029696094117184473\n",
            "0.0011865322\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g84x0QZyG2l"
      },
      "source": [
        "## Simulation 3C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvq0MP_BsuZI"
      },
      "source": [
        "Study from Yang, S., & Kim, J. K. (2020). Doubly robust inference when combining probability and non-probability samples with high dimensional. Journal of the Royal Statistical Society. Series B: Statistical Methodology, 82(2), 445‚Äì465. https://doi.org/10.1111/rssb.12354\n",
        "\n",
        "R code (source: https://github.com/shuyang1987/IntegrativeFPM)\n",
        "\n",
        "```r\n",
        "set.seed(1234)\n",
        "## population size\n",
        "N <- 10000\n",
        "## x is a p-dimensional covariate\n",
        "p <- 50\n",
        "x <- matrix( rnorm(N*p,0,1),N,p)\n",
        "## y is a continuous outcome \n",
        "beta0 <- c(1,1,1,1,1,rep(0,p-4))\n",
        "y <- cbind(1,x)%*%beta0 + rnorm(N,0,1)\n",
        "true <- mean(y)\n",
        "## y2 is a binary outcome\n",
        "ly2 <- (cbind(1,x)%*%beta0)\n",
        "ply <- exp(ly2)/(1+exp(ly2))\n",
        "y2 <- rbinom(N,1,ply)\n",
        "true2 <- mean(y2)\n",
        "## A.set is a prob sample: SRS\n",
        "## sampling probability into A is known when estimation\n",
        "nAexp <- 1000\n",
        "probA <- rep(nAexp/N,N)\n",
        "A.index <- rbinom(N,size = 1,prob = probA)\n",
        "A.loc <- which(A.index == 1)\n",
        "nA <- sum(A.index == 1)\n",
        "sw.A <- 1/probA[A.loc]\n",
        "x.A <- x[A.loc,]\n",
        "y.A <- rep(NA,nA) # y is not observed in Sample A\n",
        "y2.A <- rep(NA,nA)\n",
        "## B.set is a nonprob sample\n",
        "## sampling probability into B is unknown when estimation\n",
        "nBexp <- 2000\n",
        "alpha0 <- c(-2,1,1,1,1,rep(0,p-4))\n",
        "probB <- (1+exp(-cbind(1,x)%*%alpha0))^(-1) \n",
        "B.index <- rbinom(N,size = 1,prob = probB)\n",
        "B.loc <- which(B.index == 1)\n",
        "nB <- sum(B.index)\n",
        "x.B <- x[B.loc,]\n",
        "y.B <- y[B.loc]\n",
        "y2.B <- y2[B.loc]\n",
        "## combined dataset\n",
        "y.AB <- c(y.A,y.B)\n",
        "y2.AB <- c(y2.A,y2.B)\n",
        "x.AB <- rbind(x.A,x.B)\n",
        "deltaB <- c(rep(0,nA),rep(1,nB))\n",
        "sw <- c(sw.A,rep(1,nB))\n",
        "```"
      ]
    }
  ]
}