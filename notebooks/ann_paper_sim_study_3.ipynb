{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ann-paper-sim-study-3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNXBhEuepAv5bwhyXOVTUkX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DepartmentOfStatisticsPUE/ann-for-survey-sampling/blob/main/notebooks/ann_paper_sim_study_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsAD8OMvezI5"
      },
      "source": [
        "!apt install libomp-dev\n",
        "!pip install faiss-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Br6Vs_0fa34"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import pickle\n",
        "import faiss\n",
        "from scipy.spatial import KDTree\n",
        "from scipy.spatial.distance import euclidean\n",
        "res = faiss.StandardGpuResources() "
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF1eaae6rFUg"
      },
      "source": [
        "def kdtree_impute(tree, sample, data, y, x, eps = 0):\n",
        "  nns = tree.query(sample[:,x], k = 1, eps = eps)\n",
        "  res = np.mean(data[nns[1]][:, ys], axis = 0)\n",
        "  return res"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeEqjAOux9z2"
      },
      "source": [
        "## Simulation 3A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ImvPed5q8km"
      },
      "source": [
        "Simulation study taken from: Kim, J. K., & Wang, Z. (2018). Sampling Techniques for Big Data Analysis. International Statistical Review, 1, 1–15. https://doi.org/10.1111/insr.12290"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ik4LdbVDfMY_",
        "outputId": "24e830dc-b1e9-4caa-a8a7-129ec3729c02"
      },
      "source": [
        "np.random.seed(123)\n",
        "N = 1000000\n",
        "x1 = np.random.normal(loc=1.0,scale=1.0,size=N)\n",
        "x2 = np.random.exponential(scale=1.0, size = N)\n",
        "epsilon = np.random.normal(size=N)\n",
        "\n",
        "### target variables\n",
        "y1 = 1 + x1 + x2 + epsilon\n",
        "y2 = 0.5*(x1 - 1.5)**2 + x2 + epsilon\n",
        "## propensity scores\n",
        "p1 = np.exp(x2) / (1 + np.exp(x2))\n",
        "p2 = np.exp(-0.5 + 0.5*(x2-2)**2) / (1 + np.exp(-0.5 + 0.5*(x2-2)**2))\n",
        "\n",
        "data = np.column_stack((x1,x2,y1,y2,p1,p2)).astype('float32')\n",
        "data[:3]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.0856306 ,  0.5546646 ,  0.90054107,  1.2432839 ,  0.63521713,\n",
              "         0.632858  ],\n",
              "       [ 1.9973454 ,  1.1975824 ,  4.455222  ,  1.5815529 ,  0.7680944 ,\n",
              "         0.4556015 ],\n",
              "       [ 1.2829785 ,  0.84342945,  3.0256119 ,  0.76618266,  0.699187  ,\n",
              "         0.542107  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xtafAIGfqcI"
      },
      "source": [
        "R = 500\n",
        "xs = [0,1]\n",
        "ys = [2,3]\n",
        "ps = [4,5]\n",
        "\n",
        "results_faiss_500 = np.zeros(shape = (R, 2))\n",
        "results_faiss_1000 = np.zeros(shape = (R, 2))\n",
        "results_kdtree_500 = np.zeros(shape = (R, 2))\n",
        "results_kdtree_1000 = np.zeros(shape = (R, 2))\n",
        "\n",
        "for r in range(R):\n",
        "  print(r)\n",
        "  np.random.seed(r)\n",
        "  ## big data sample\n",
        "  big_p1 = np.random.binomial(n=1, p = p1, size = N)\n",
        "  big_p2 = np.random.binomial(n=1, p = p2, size = N)    \n",
        "  ## random samples\n",
        "  s500 = np.random.choice(a = data.shape[0], size = 500, replace = False)\n",
        "  s1000 = np.random.choice(a = data.shape[0], size = 1000, replace = False)\n",
        "  ## kdtree (exact)\n",
        "  kdtree = KDTree(data[big_p1==1][:, xs], leafsize = 10)\n",
        "  results_kdtree_500[r, :] = kdtree_impute(kdtree, data[s500], data[big_p1==1], ys, xs)\n",
        "  results_kdtree_1000[r, :] = kdtree_impute(kdtree, data[s1000], data[big_p1==1], ys, xs)\n",
        "  ## faiss\n",
        "  big_data = data[big_p1==1][:, xs].copy()\n",
        "  sam_data_500 = data[s500][:, xs].copy()\n",
        "  sam_data_1000 = data[s1000][:, xs].copy()\n",
        "  index_flat = faiss.IndexFlatL2(len(xs))\n",
        "  gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)\n",
        "  gpu_index_flat.add(big_data)\n",
        "  D_500, I_500 = gpu_index_flat.search(sam_data_500, k = 1) \n",
        "  D_1000, I_1000 = gpu_index_flat.search(sam_data_1000, k = 1) \n",
        "  ind_500 = [i[0] for i in I_500]\n",
        "  ind_1000 = [i[0] for i in I_1000]\n",
        "  results_faiss_500[r,:]=np.mean(data[big_p1==1][ind_500][:, ys], axis=0)\n",
        "  results_faiss_1000[r,:]=np.mean(data[big_p1==1][ind_1000][:, ys], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhEJCYsWlZNW",
        "outputId": "f24d592a-1f45-47a7-b38e-6283f8c097fe"
      },
      "source": [
        "expected = np.stack(\n",
        "    [np.mean(results_kdtree_500, axis=0),\n",
        "     np.mean(results_faiss_500, axis=0),\n",
        "     np.mean(results_kdtree_1000, axis=0),\n",
        "     np.mean(results_faiss_1000, axis=0)\n",
        "     ]\n",
        ") \n",
        "\n",
        "stderrs =  np.stack(\n",
        "    [np.std(results_kdtree_500, axis=0),\n",
        "     np.std(results_faiss_500, axis=0),\n",
        "     np.std(results_kdtree_1000, axis=0),\n",
        "     np.std(results_faiss_1000, axis=0)\n",
        "     ]\n",
        ")\n",
        "\n",
        "bias = expected - np.mean(data[:,ys], axis=0)\n",
        "mse = bias**2 + stderrs**2\n",
        "\n",
        "print(\"===== bias =====\")\n",
        "print(bias)\n",
        "print(\"===== se =====\")\n",
        "print(stderrs)\n",
        "print(\"===== mse =====\")\n",
        "print(mse)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== bias =====\n",
            "[[ 0.00424795 -0.00285448]\n",
            " [ 0.00378274 -0.00331977]\n",
            " [ 0.00329126  0.00082333]\n",
            " [ 0.00325391  0.00078617]]\n",
            "===== se =====\n",
            "[[0.07272113 0.07345612]\n",
            " [0.07295542 0.07315786]\n",
            " [0.05202406 0.04801981]\n",
            " [0.05191877 0.04749557]]\n",
            "===== mse =====\n",
            "[[0.00530641 0.00540395]\n",
            " [0.0053368  0.00536309]\n",
            " [0.00271734 0.00230658]\n",
            " [0.00270615 0.00225645]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czxaj3oawu6m"
      },
      "source": [
        "## save results\n",
        "results = {\n",
        "    \"results_kdtree_500\" : pd.DataFrame(results_kdtree_500),\n",
        "    \"results_faiss_500\" : pd.DataFrame(results_faiss_500),\n",
        "    \"results_kdtree_1000\": pd.DataFrame(results_kdtree_1000),\n",
        "    \"results_faiss_1000\": pd.DataFrame(results_faiss_1000),\n",
        "           }\n",
        "\n",
        "f = open(\"kdtree_faiss_500_1000k.pkl\",\"wb\")\n",
        "pickle.dump(results,f)\n",
        "f.close()"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQNLdp9IyGE6"
      },
      "source": [
        "## Simulation 3B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGA2ywP5reji"
      },
      "source": [
        "Modified case from: Yang, S., & Kim, J. K. (2019). Nearest neighbour imputation for general parameter estimation in survey sampling. In The Econometrics of Complex Survey Data: Theory and Applications (Vol. 39, pp. 209–234)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93ciOzNyGAEY"
      },
      "source": [
        "def kdtree_impute2(tree, data_obs, data_not, y, x, N, eps = 0):\n",
        "  nns = tree.query(data_not[:,xs], k = 1, eps = eps)\n",
        "  res = (np.sum(data_obs[nns[1]][:, ys], axis = 0) + np.sum(data_obs[:, ys], axis = 0)) / N\n",
        "  return res"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krpxc0VqDpgK",
        "outputId": "426c5576-1628-481a-cce1-c01ce6966202"
      },
      "source": [
        "np.random.seed(123)\n",
        "N = 50000\n",
        "x1 = np.random.uniform(size = N)\n",
        "x2 = np.random.uniform(size = N)\n",
        "x3 = np.random.uniform(size = N)\n",
        "x4 = np.random.normal(size = N)\n",
        "x5 = np.random.normal(size = N)\n",
        "x6 = np.random.normal(size = N)\n",
        "epsilon = np.random.normal(size=N)\n",
        "\n",
        "### target variables\n",
        "y1 = -1 + x1 + x2 + epsilon\n",
        "y2 = -1.5 + x1 + x2 + x3 + x4 + epsilon\n",
        "y3 = -1.5 + x1 + x2 + x3 + x4 + x5 + x6 + epsilon\n",
        "y4 = -1 + x1 + x2 + x1**2 + x2**2 -2/3 + epsilon\n",
        "y5 = -1 + x1 + x2 + x3 + x4 + x1**2 + x2**2 -2/3 + epsilon\n",
        "y6 = -1 + x1 + x2 + x3 + x4 + x5 + x6 + x1**2 + x2**2 -2/3 + epsilon\n",
        "\n",
        "## propensity scores\n",
        "p1 = np.exp(1 + x1 + x2 + x3 + x4 + x5 + x6) / (1 + np.exp(1 + x1 + x2 + x3 + x4 + x5 + x6))\n",
        "p2 = np.exp(1 + x1 + x2) / (1 + np.exp(1 + x1 + x2))\n",
        "\n",
        "data = np.column_stack((x1,x2,x3,x4,x5,x6,y1,y2,y3,y4,y5,y6)).astype('float32')\n",
        "data[:3]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.6964692 ,  0.36086547,  0.20932843,  0.47665665,  0.80429375,\n",
              "        -0.9894137 ,  0.42543107,  0.61141616,  0.42629617,  0.3740576 ,\n",
              "         1.0600427 ,  0.87492275],\n",
              "       [ 0.28613934,  0.22535679,  0.2937351 ,  0.6701647 ,  1.2931948 ,\n",
              "         1.033963  ,  0.25331086,  0.71721065,  3.0443685 , -0.2806944 ,\n",
              "         0.6832054 ,  3.010363  ],\n",
              "       [ 0.22685145,  0.50813043,  0.05571789,  0.5033514 ,  1.5591047 ,\n",
              "         0.13504769,  0.36729714,  0.42636642,  2.1205187 ,  0.0102886 ,\n",
              "         0.5693579 ,  2.2635102 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi0PYu6QK0cJ",
        "outputId": "c5378b08-f624-45eb-cdf9-b73f3ade39fc"
      },
      "source": [
        "\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.51176731996"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQWApDb3EptG",
        "outputId": "9c980caa-6ae6-466a-a934-65ca860b9fbc"
      },
      "source": [
        "R = 500\n",
        "xs = [0,1,2,3,4,5]\n",
        "ys = [6,7,8,9,10,11]\n",
        "\n",
        "results_faiss = np.zeros(shape = (R, 6))\n",
        "results_kdtree = np.zeros(shape = (R, 6))\n",
        "results_pmm = np.zeros(shape = (R, 6))\n",
        "\n",
        "for r in range(R):\n",
        "  print(r)\n",
        "  np.random.seed(r)\n",
        "  ## big data sample\n",
        "  big_p1 = np.random.binomial(n=1, p = p1, size = N)\n",
        "  ## data\n",
        "  data_obs = data[big_p1 == 1].copy()\n",
        "  data_not = data[big_p1 != 1].copy()\n",
        "  ## kdtree (exact)\n",
        "  #kdtree = KDTree(data_obs[:, xs], leafsize = 10)\n",
        "  #results_kdtree[r, :] = kdtree_impute2(kdtree, data_obs, data_not, ys, xs, N)\n",
        "  ## predictive mean matching for y1\n",
        "  X_obs = data_obs[:, xs]\n",
        "  X_obs = sm.add_constant(X_obs)\n",
        "  y_obs = data_obs[:, ys[5]]\n",
        "  ols_y = sm.OLS(y_obs, X_obs).fit()\n",
        "  X_not = data_not[:, xs]\n",
        "  X_not = sm.add_constant(X_not)\n",
        "  y_not = np.dot(X_not, ols_y.params)\n",
        "  results_pmm[r, 5] = (np.sum(np.array([y_obs[np.argmin(np.sqrt((y_obs - row)**2))] for row in y_not])) + sum(y_obs)) / N\n",
        "  ## faiss\n",
        "  data_obs_faiss = data_obs[:, xs].copy()\n",
        "  data_not_faiss = data_not[:, xs].copy()\n",
        "  index_flat = faiss.IndexFlatL2(len(xs))\n",
        "  gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)\n",
        "  gpu_index_flat.add(data_obs_faiss)\n",
        "  dists, inds = gpu_index_flat.search(data_not_faiss, k = 1) \n",
        "  inds_imp = [i[0] for i in inds]\n",
        "  results_faiss[r,:]= (np.sum(data_obs[inds_imp][:, ys], axis=0) + np.sum(data_obs[:, ys], axis=0)) / N"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHg_WgtWIVKU",
        "outputId": "86c9553e-e4d2-4aad-ed13-cce7e6161085"
      },
      "source": [
        "expected = np.stack(\n",
        "    [#np.mean(results_kdtree, axis=0),\n",
        "     np.mean(results_faiss, axis=0)\n",
        "     ]\n",
        ") \n",
        "\n",
        "stderrs =  np.stack(\n",
        "    [#np.std(results_kdtree, axis=0),\n",
        "     np.std(results_faiss, axis=0)\n",
        "     ]\n",
        ")\n",
        "\n",
        "bias = expected - np.mean(data[:,ys], axis=0)\n",
        "mse = bias**2 + stderrs**2\n",
        "\n",
        "print(\"===== bias =====\")\n",
        "print(bias)\n",
        "print(\"===== se =====\")\n",
        "print(stderrs)\n",
        "print(\"===== mse =====\")\n",
        "print(mse)\n",
        "print(expected)\n",
        "print(np.mean(results_pmm[:, 5]))\n",
        "print(np.std(results_pmm[:, 5]))"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== bias =====\n",
            "[[849.00727166 140.62519024 178.91123984 762.39777878   2.4278875\n",
            "    3.98481115]]\n",
            "===== se =====\n",
            "[[0.00308666 0.00313541 0.00326809 0.00316385 0.00319099 0.00330361]]\n",
            "===== mse =====\n",
            "[[2.74536077e-05 1.14547982e-04 3.43846135e-04 5.00142213e-05\n",
            "  1.62066949e-04 4.24783205e-04]]\n",
            "[[0.00473262 0.01751003 0.028455   0.0071545  0.5199319  0.53087687]]\n",
            "0.511664524975071\n",
            "0.002141024609639731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g84x0QZyG2l"
      },
      "source": [
        "## Simulation 3C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvq0MP_BsuZI"
      },
      "source": [
        "Study from Yang, S., & Kim, J. K. (2020). Doubly robust inference when combining probability and non-probability samples with high dimensional. Journal of the Royal Statistical Society. Series B: Statistical Methodology, 82(2), 445–465. https://doi.org/10.1111/rssb.12354\n",
        "\n",
        "R code (source: https://github.com/shuyang1987/IntegrativeFPM)\n",
        "\n",
        "```r\n",
        "set.seed(1234)\n",
        "## population size\n",
        "N <- 10000\n",
        "## x is a p-dimensional covariate\n",
        "p <- 50\n",
        "x <- matrix( rnorm(N*p,0,1),N,p)\n",
        "## y is a continuous outcome \n",
        "beta0 <- c(1,1,1,1,1,rep(0,p-4))\n",
        "y <- cbind(1,x)%*%beta0 + rnorm(N,0,1)\n",
        "true <- mean(y)\n",
        "## y2 is a binary outcome\n",
        "ly2 <- (cbind(1,x)%*%beta0)\n",
        "ply <- exp(ly2)/(1+exp(ly2))\n",
        "y2 <- rbinom(N,1,ply)\n",
        "true2 <- mean(y2)\n",
        "## A.set is a prob sample: SRS\n",
        "## sampling probability into A is known when estimation\n",
        "nAexp <- 1000\n",
        "probA <- rep(nAexp/N,N)\n",
        "A.index <- rbinom(N,size = 1,prob = probA)\n",
        "A.loc <- which(A.index == 1)\n",
        "nA <- sum(A.index == 1)\n",
        "sw.A <- 1/probA[A.loc]\n",
        "x.A <- x[A.loc,]\n",
        "y.A <- rep(NA,nA) # y is not observed in Sample A\n",
        "y2.A <- rep(NA,nA)\n",
        "## B.set is a nonprob sample\n",
        "## sampling probability into B is unknown when estimation\n",
        "nBexp <- 2000\n",
        "alpha0 <- c(-2,1,1,1,1,rep(0,p-4))\n",
        "probB <- (1+exp(-cbind(1,x)%*%alpha0))^(-1) \n",
        "B.index <- rbinom(N,size = 1,prob = probB)\n",
        "B.loc <- which(B.index == 1)\n",
        "nB <- sum(B.index)\n",
        "x.B <- x[B.loc,]\n",
        "y.B <- y[B.loc]\n",
        "y2.B <- y2[B.loc]\n",
        "## combined dataset\n",
        "y.AB <- c(y.A,y.B)\n",
        "y2.AB <- c(y2.A,y2.B)\n",
        "x.AB <- rbind(x.A,x.B)\n",
        "deltaB <- c(rep(0,nA),rep(1,nB))\n",
        "sw <- c(sw.A,rep(1,nB))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERf_wTZ3reNq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}