{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ann-paper-simulation-2-data-integration.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxKAxtiWcS1fHnsng1h4oq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DepartmentOfStatisticsPUE/ann-for-survey-sampling/blob/main/ann_paper_simulation_2_data_integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWOjSQXW4A7d"
      },
      "source": [
        "!apt install libomp-dev\n",
        "!pip install faiss-gpu\n",
        "!pip install n2\n",
        "!pip install scann\n",
        "!pip install annoy ## takes minutes to add data and index\n",
        "!pip install pyflann-py3\n",
        "## !pip install pynndescent -- not suitable for PMM 1d dimension: gets error \"no suitable hyperplains were found\"\n",
        "\n",
        "## this line cleanes information about installing\n",
        "## comment these lines if you want to see the progress \n",
        "from IPython.display import clear_output \n",
        "clear_output()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAU8WQID4TFL"
      },
      "source": [
        "## standard modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "## vis\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "## linear regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "## ann modules\n",
        "import scann\n",
        "import faiss\n",
        "from pyflann import *\n",
        "from annoy import AnnoyIndex\n",
        "from n2 import HnswIndex\n",
        "from scipy.spatial import cKDTree\n",
        "from pynndescent import NNDescent\n",
        "\n",
        "## serialization\n",
        "import pickle"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsprLzxc4U4s"
      },
      "source": [
        "def kdtree_impute_di(y_pred, y_pred_miss, y):\n",
        "  tree = cKDTree(y_pred, leafsize = 100, balanced_tree=True)\n",
        "  dists, indx = tree.query(y_pred_miss, k = 1, eps = 0)\n",
        "  res = np.mean(y[indx])\n",
        "  return res\n",
        "\n",
        "def faiss_impute_di(y_pred, y_pred_miss, y, gpu = True, voronoi = False):\n",
        "  index_flat = faiss.IndexFlatL2(2)\n",
        "\n",
        "  if voronoi:\n",
        "    index_flat = faiss.IndexIVFFlat(index_flat, 2, 1000)\n",
        "\n",
        "  if gpu:\n",
        "    gpu_faiss = faiss.StandardGpuResources() \n",
        "    index_flat = faiss.index_cpu_to_gpu(gpu_faiss, 0, index_flat)\n",
        "  \n",
        "  if voronoi:\n",
        "    index_flat.train(y_pred)\n",
        "\n",
        "  index_flat.add(y_pred)\n",
        "  dists, indx = index_flat.search(y_pred_miss, k = 1) \n",
        "  res = np.mean(y[indx])\n",
        "  return res\n",
        "\n",
        "def annoy_impute_di(y_pred, y_pred_miss, y, trees = 50):\n",
        "  t = AnnoyIndex(2, \"euclidean\") \n",
        "  for i in range(len(y_pred)):\n",
        "    t.add_item(i, y_pred[i,:]) \n",
        "\n",
        "  t.build(trees)\n",
        "  indx = np.array([t.get_nns_by_vector(i, 1) for i in y_pred_miss])\n",
        "  res = np.mean(y[indx])\n",
        "  return res\n",
        "\n",
        "def n2_impute_di(y_pred, y_pred_miss, y, trees = 50):\n",
        "  t = HnswIndex(2, \"euclidean\") \n",
        "  for i in y_pred:\n",
        "    t.add_data(i)\n",
        "\n",
        "  t.build(m=5, n_threads=-1)\n",
        "  indx = t.batch_search_by_vectors(y_pred_miss, 1)\n",
        "  res = np.mean(y[indx])\n",
        "  return res\n",
        "\n",
        "def flann_impute_di(y_pred, y_pred_miss, y):\n",
        "  flann = FLANN()\n",
        "  indx, dists = flann.nn(y_pred, y_pred_miss, 1, \n",
        "                       algorithm=\"kdtree\", \n",
        "                       #branching=32, iterations=7, checks=16, \n",
        "                       random_seed = 1)\n",
        "  res = np.mean(y[indx])\n",
        "  return res\n",
        "\n",
        "def scann_impute_di(y_pred, y_pred_miss, y):\n",
        "  searcher = scann.scann_ops_pybind.builder(y_pred, 1, \"squared_l2\").tree(\n",
        "      num_leaves=1000, num_leaves_to_search=50, training_sample_size=5000).score_ah(\n",
        "          2, anisotropic_quantization_threshold=0.2).reorder(10).build()\n",
        "  indx, nns = searcher.search_batched(y_pred_miss)\n",
        "  res = np.mean(y[indx])\n",
        "  return res"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpp8iMSl4dCP"
      },
      "source": [
        "Simulation study taken from: Kim, J. K., & Wang, Z. (2018). Sampling Techniques for Big Data Analysis. International Statistical Review, 1, 1â€“15. https://doi.org/10.1111/insr.12290"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yShdyhnt4X4F",
        "outputId": "5b276c2c-56b0-49c0-9f14-fa8a64834b5f"
      },
      "source": [
        "np.random.seed(123) \n",
        "N = 1000000\n",
        "x1 = np.random.normal(loc=1.0,scale=1.0,size=N)\n",
        "x2 = np.random.exponential(scale=1.0, size = N)\n",
        "epsilon = np.random.normal(size=N)\n",
        "\n",
        "### target variables\n",
        "y1 = 1 + x1 + x2 + epsilon\n",
        "y2 = 0.5*(x1 - 1.5)**2 + x2 + epsilon\n",
        "## propensity scores\n",
        "p1 = np.exp(x2) / (1 + np.exp(x2))\n",
        "p2 = np.exp(-0.5 + 0.5*(x2-2)**2) / (1 + np.exp(-0.5 + 0.5*(x2-2)**2))\n",
        "\n",
        "data = np.column_stack((x1,x2,y1,y2,p1,p2)).astype('float32')\n",
        "data[:3]"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.0856306 ,  0.5546646 ,  0.90054107,  1.2432839 ,  0.63521713,\n",
              "         0.632858  ],\n",
              "       [ 1.9973454 ,  1.1975824 ,  4.455222  ,  1.5815529 ,  0.7680944 ,\n",
              "         0.4556015 ],\n",
              "       [ 1.2829785 ,  0.84342945,  3.0256119 ,  0.76618266,  0.699187  ,\n",
              "         0.542107  ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "DQuGGfay4lzL",
        "outputId": "ac2c24f2-1ebb-41c2-daee-db8eca5f9dad"
      },
      "source": [
        "R = 500\n",
        "xs = [0,1]\n",
        "ys = [2,3]\n",
        "ps = [4,5]\n",
        "\n",
        "results_naive_500 = np.zeros(shape = (R, 3))\n",
        "results_naive_1000 = np.zeros(shape = (R, 3))\n",
        "results_faiss_500 = np.zeros(shape = (R, 3))\n",
        "results_faiss_1000 = np.zeros(shape = (R, 3))\n",
        "results_faiss_v_500 = np.zeros(shape = (R, 3))\n",
        "results_faiss_v_1000 = np.zeros(shape = (R, 3))\n",
        "results_kdtree_500 = np.zeros(shape = (R, 3))\n",
        "results_kdtree_1000 = np.zeros(shape = (R, 3))\n",
        "results_scann_500 = np.zeros(shape = (R, 3))\n",
        "results_scann_1000 = np.zeros(shape = (R, 3))\n",
        "results_flann_500 = np.zeros(shape = (R, 3))\n",
        "results_flann_1000 = np.zeros(shape = (R, 3))\n",
        "\n",
        "for r in range(R):\n",
        "  print(r)\n",
        "  np.random.seed(r)\n",
        "  ## big data sample\n",
        "  big_p1 = np.random.binomial(n=1, p = p1, size = N)\n",
        "  big_p2 = np.random.binomial(n=1, p = p2, size = N)    \n",
        "  ## random samples\n",
        "  s500 = np.random.choice(a = data.shape[0], size = 500, replace = False)\n",
        "  s1000 = np.random.choice(a = data.shape[0], size = 1000, replace = False)\n",
        "  \n",
        "  ## naive\n",
        "  results_naive_500[r, 0] = np.mean(data[big_p1==1][:, ys[0]])\n",
        "  results_naive_500[r, 1] = np.mean(data[big_p2==1][:, ys[0]])\n",
        "  results_naive_500[r, 2] = np.mean(data[big_p1==1][:, ys[1]])\n",
        "  results_naive_1000[r, 0] = np.mean(data[big_p1==1][:, ys[0]])\n",
        "  results_naive_1000[r, 1] = np.mean(data[big_p2==1][:, ys[0]])\n",
        "  results_naive_1000[r, 2] = np.mean(data[big_p1==1][:, ys[1]])\n",
        "\n",
        "  ## imputation by kdtree\n",
        "  results_kdtree_500[r,0]=kdtree_impute_di(data[big_p1==1][:, xs], data[s500][:, xs], data[big_p1==1][:, ys[0]])\n",
        "  results_kdtree_500[r,1]=kdtree_impute_di(data[big_p2==1][:, xs], data[s500][:, xs], data[big_p2==1][:, ys[0]])\n",
        "  results_kdtree_500[r,2]=kdtree_impute_di(data[big_p1==1][:, xs], data[s500][:, xs], data[big_p1==1][:, ys[1]])\n",
        "  results_kdtree_1000[r,0]=kdtree_impute_di(data[big_p1==1][:, xs], data[s1000][:, xs], data[big_p1==1][:, ys[0]])\n",
        "  results_kdtree_1000[r,1]=kdtree_impute_di(data[big_p2==1][:, xs], data[s1000][:, xs], data[big_p2==1][:, ys[0]])\n",
        "  results_kdtree_1000[r,2]=kdtree_impute_di(data[big_p1==1][:, xs], data[s1000][:, xs], data[big_p1==1][:, ys[1]])\n",
        "  \n",
        "  ## imputation by faiss\n",
        "  results_faiss_500[r,0]=faiss_impute_di(data[big_p1==1][:, xs].copy(), data[s500][:, xs].copy(), data[big_p1==1][:, ys[0]].copy())\n",
        "  results_faiss_500[r,1]=faiss_impute_di(data[big_p2==1][:, xs].copy(), data[s500][:, xs].copy(), data[big_p2==1][:, ys[0]].copy())\n",
        "  results_faiss_500[r,2]=faiss_impute_di(data[big_p1==1][:, xs].copy(), data[s500][:, xs].copy(), data[big_p1==1][:, ys[1]].copy())\n",
        "  results_faiss_1000[r,0]=faiss_impute_di(data[big_p1==1][:, xs].copy(), data[s1000][:, xs].copy(), data[big_p1==1][:, ys[0]].copy())\n",
        "  results_faiss_1000[r,1]=faiss_impute_di(data[big_p2==1][:, xs].copy(), data[s1000][:, xs].copy(), data[big_p2==1][:, ys[0]].copy())\n",
        "  results_faiss_1000[r,2]=faiss_impute_di(data[big_p1==1][:, xs].copy(), data[s1000][:, xs].copy(), data[big_p1==1][:, ys[1]].copy())\n",
        "  \n",
        "  ## imputation by faiss with voronoi\n",
        "  results_faiss_v_500[r,0]=faiss_impute_di(data[big_p1==1][:, xs].copy(), data[s500][:, xs].copy(), data[big_p1==1][:, ys[0]].copy(), voronoi=True)\n",
        "  results_faiss_v_500[r,1]=faiss_impute_di(data[big_p2==1][:, xs].copy(), data[s500][:, xs].copy(), data[big_p2==1][:, ys[0]].copy(), voronoi=True)\n",
        "  results_faiss_v_500[r,2]=faiss_impute_di(data[big_p1==1][:, xs].copy(), data[s500][:, xs].copy(), data[big_p1==1][:, ys[1]].copy(), voronoi=True)\n",
        "  results_faiss_v_1000[r,0]=faiss_impute_di(data[big_p1==1][:, xs].copy(), data[s1000][:, xs].copy(), data[big_p1==1][:, ys[0]].copy(), voronoi=True)\n",
        "  results_faiss_v_1000[r,1]=faiss_impute_di(data[big_p2==1][:, xs].copy(), data[s1000][:, xs].copy(), data[big_p2==1][:, ys[0]].copy(), voronoi=True)\n",
        "  results_faiss_v_1000[r,2]=faiss_impute_di(data[big_p1==1][:, xs].copy(), data[s1000][:, xs].copy(), data[big_p1==1][:, ys[1]].copy(), voronoi=True)\n",
        "\n",
        "  ## imputation by scann\n",
        "  results_scann_500[r,0]=scann_impute_di(data[big_p1==1][:, xs], data[s500][:, xs], data[big_p1==1][:, ys[0]])\n",
        "  results_scann_500[r,1]=scann_impute_di(data[big_p2==1][:, xs], data[s500][:, xs], data[big_p2==1][:, ys[0]])\n",
        "  results_scann_500[r,2]=scann_impute_di(data[big_p1==1][:, xs], data[s500][:, xs], data[big_p1==1][:, ys[1]])\n",
        "  results_scann_1000[r,0]=scann_impute_di(data[big_p1==1][:, xs], data[s1000][:, xs], data[big_p1==1][:, ys[0]])\n",
        "  results_scann_1000[r,1]=scann_impute_di(data[big_p2==1][:, xs], data[s1000][:, xs], data[big_p2==1][:, ys[0]])\n",
        "  results_scann_1000[r,2]=scann_impute_di(data[big_p1==1][:, xs], data[s1000][:, xs], data[big_p1==1][:, ys[1]])\n",
        "\n",
        "  ## imputation by flann\n",
        "  results_flann_500[r,0]=flann_impute_di(data[big_p1==1][:, xs], data[s500][:, xs], data[big_p1==1][:, ys[0]])\n",
        "  results_flann_500[r,1]=flann_impute_di(data[big_p2==1][:, xs], data[s500][:, xs], data[big_p2==1][:, ys[0]])\n",
        "  results_flann_500[r,2]=flann_impute_di(data[big_p1==1][:, xs], data[s500][:, xs], data[big_p1==1][:, ys[1]])\n",
        "  results_flann_1000[r,0]=flann_impute_di(data[big_p1==1][:, xs], data[s1000][:, xs], data[big_p1==1][:, ys[0]])\n",
        "  results_flann_1000[r,1]=flann_impute_di(data[big_p2==1][:, xs], data[s1000][:, xs], data[big_p2==1][:, ys[0]])\n",
        "  results_flann_1000[r,2]=flann_impute_di(data[big_p1==1][:, xs], data[s1000][:, xs], data[big_p1==1][:, ys[1]])"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-419a57f8989c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0mresults_scann_500\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscann_impute_di\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbig_p1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbig_p1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0mresults_scann_1000\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscann_impute_di\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbig_p1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbig_p1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m   \u001b[0mresults_scann_1000\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscann_impute_di\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbig_p2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbig_p2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0mresults_scann_1000\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscann_impute_di\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbig_p1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbig_p1\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-72-a26d826061e3>\u001b[0m in \u001b[0;36mscann_impute_di\u001b[0;34m(y_pred, y_pred_miss, y)\u001b[0m\n\u001b[1;32m     55\u001b[0m   searcher = scann.scann_ops_pybind.builder(y_pred, 1, \"squared_l2\").tree(\n\u001b[1;32m     56\u001b[0m       \u001b[0mnum_leaves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_leaves_to_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_sample_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_ah\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m           2, anisotropic_quantization_threshold=0.2).reorder(10).build()\n\u001b[0m\u001b[1;32m     58\u001b[0m   \u001b[0mindx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_miss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scann/scann_ops/py/scann_builder.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"build() called but no builder lambda was set.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scann/scann_ops/py/scann_ops_pybind.py\u001b[0m in \u001b[0;36mbuilder_lambda\u001b[0;34m(db, config, training_threads, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuilder_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_searcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m   return scann_builder.ScannBuilder(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scann/scann_ops/py/scann_ops_pybind.py\u001b[0m in \u001b[0;36mcreate_searcher\u001b[0;34m(db, scann_config, training_threads)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_searcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscann_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m   return ScannSearcher(\n\u001b[0;32m---> 87\u001b[0;31m       scann_pybind.ScannNumpy(db, scann_config, training_threads))\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZxbyafcD7pX",
        "outputId": "65b867eb-ef6d-489c-8552-47e6493db6d9"
      },
      "source": [
        "y_trues = [np.mean(y1), np.mean(y1), np.mean(y2)]\n",
        "\n",
        "mse_500 = [\n",
        " np.std(results_naive_500, axis = 0)**2 + (np.mean(results_naive_500, axis = 0) - y_trues)**2,\n",
        " np.std(results_kdtree_500, axis = 0)**2 + (np.mean(results_kdtree_500, axis = 0) - y_trues)**2,\n",
        " np.std(results_faiss_500, axis = 0)**2 + (np.mean(results_faiss_500, axis = 0) - y_trues)**2,\n",
        " np.std(results_flann_500, axis = 0)**2 + (np.mean(results_flann_500, axis = 0) - y_trues)**2,\n",
        " np.std(results_scann_500, axis = 0)**2 + (np.mean(results_scann_500, axis = 0) - y_trues)**2\n",
        " ]\n",
        "\n",
        "np.sqrt(mse_500)\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.18627488, 0.09831804, 0.186431  ],\n",
              "       [0.08211612, 0.07099447, 0.0813127 ],\n",
              "       [0.08163982, 0.07074112, 0.0812208 ],\n",
              "       [0.08133967, 0.07058238, 0.08079635],\n",
              "       [0.10292541, 0.10698985, 0.11651488]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u38PVRWuUZgL",
        "outputId": "a97a80bc-a799-4c86-ca32-101dd78ef1a1"
      },
      "source": [
        "mse_1000 = [\n",
        "np.std(results_naive_1000, axis = 0)**2 + (np.mean(results_naive_1000, axis = 0) - y_trues)**2,\n",
        " np.std(results_kdtree_1000, axis = 0)**2 + (np.mean(results_kdtree_1000, axis = 0) - y_trues)**2,\n",
        " np.std(results_faiss_1000, axis = 0)**2 + (np.mean(results_faiss_1000, axis = 0) - y_trues)**2,\n",
        " np.std(results_flann_1000, axis = 0)**2 + (np.mean(results_flann_1000, axis = 0) - y_trues)**2,\n",
        " np.std(results_scann_1000, axis = 0)**2 + (np.mean(results_scann_1000, axis = 0) - y_trues)**2\n",
        " ]\n",
        "np.sqrt(mse_1000)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.18627488, 0.09831804, 0.186431  ],\n",
              "       [0.0444269 , 0.04747939, 0.0470238 ],\n",
              "       [0.044689  , 0.04701806, 0.04703901],\n",
              "       [0.04480808, 0.04678452, 0.04711393],\n",
              "       [0.07262391, 0.08552078, 0.09067404]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJv-yVrUNVeQ"
      },
      "source": [
        "results = {\n",
        "    \"data\": pd.DataFrame(data),\n",
        "    \"results_naive_500\" : pd.DataFrame(results_naive_500),\n",
        "    \"results_naive_1000\" : pd.DataFrame(results_naive_1000),\n",
        "    \"results_faiss_500\" : pd.DataFrame(results_faiss_500),\n",
        "    \"results_faiss_1000\" : pd.DataFrame(results_faiss_1000),\n",
        "    \"results_faiss_v_500\" : pd.DataFrame(results_faiss_v_500),\n",
        "    \"results_faiss_v_1000\" : pd.DataFrame(results_faiss_v_1000),\n",
        "    \"results_kdtree_500\" : pd.DataFrame(results_kdtree_500),\n",
        "    \"results_kdtree_1000\" : pd.DataFrame(results_kdtree_1000),\n",
        "    \"results_scann_500\" : pd.DataFrame(results_scann_500),\n",
        "    \"results_scann_1000\" : pd.DataFrame(results_scann_1000),\n",
        "    \"results_flann_500\" : pd.DataFrame(results_flann_500),\n",
        "    \"results_flann_1000\" : pd.DataFrame(results_flann_1000),\n",
        "          }\n",
        "\n",
        "f = open(\"sim2-results.pkl\",\"wb\")\n",
        "pickle.dump(results,f)\n",
        "f.close()"
      ],
      "execution_count": 109,
      "outputs": []
    }
  ]
}