{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ann-paper-simulation-1-properties.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMB1YcHwsgRMgN6zUIRkDa9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DepartmentOfStatisticsPUE/ann-for-survey-sampling/blob/main/ann_paper_simulation_1_properties.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaOylZ_wyYzY"
      },
      "source": [
        "## About\n",
        "\n",
        "This notebook covers simulation study to assess the performance of predictive mean imputation based on exact and approximate nearest neigbours. \n",
        "\n",
        "**Warning**: before runing this scripts go to `Runtime` -> `Change runtime type` and set it to `GPU`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAJ8fCEMyxzQ"
      },
      "source": [
        "## Install requested modules\n",
        "\n",
        "Please note that this may take some time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIGVVBPyyPUw"
      },
      "source": [
        "!apt install libomp-dev\n",
        "!pip install faiss-gpu\n",
        "!pip install n2\n",
        "!pip install scann\n",
        "!pip install annoy ## takes minutes to add data and index\n",
        "!pip install pyflann-py3\n",
        "## !pip install pynndescent -- not suitable for PMM 1d dimension: gets error \"no suitable hyperplains were found\"\n",
        "\n",
        "## this line cleanes information about installing\n",
        "## comment these lines if you want to see the progress \n",
        "from IPython.display import clear_output \n",
        "clear_output()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pMhr7DWznfJ"
      },
      "source": [
        "## Import requested modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYX-DeZRzqzU"
      },
      "source": [
        "## standard modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "## linear regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "## ann modules\n",
        "import scann\n",
        "import faiss\n",
        "from pyflann import *\n",
        "from annoy import AnnoyIndex\n",
        "from n2 import HnswIndex\n",
        "from scipy.spatial import cKDTree\n",
        "from pynndescent import NNDescent"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkdqmjIT195F"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHUQPEzS1_a3"
      },
      "source": [
        "def kdtree_impute(y_pred, y_pred_miss, y):\n",
        "  tree = cKDTree(y_pred, leafsize = 100, balanced_tree=True)\n",
        "  dists, indx = tree.query(y_pred_miss, k = 1, eps = 0)\n",
        "  res = (np.sum(y) + np.sum(y[indx])) / (len(y_pred) + len(y_pred_miss))\n",
        "  return res\n",
        "\n",
        "def faiss_impute(y_pred, y_pred_miss, y, gpu = True, voronoi = False):\n",
        "  index_flat = faiss.IndexFlatL2(1)\n",
        "\n",
        "  if voronoi:\n",
        "    index_flat = faiss.IndexIVFFlat(index_flat, 1, 1000)\n",
        "\n",
        "  if gpu:\n",
        "    gpu_faiss = faiss.StandardGpuResources() \n",
        "    index_flat = faiss.index_cpu_to_gpu(gpu_faiss, 0, index_flat)\n",
        "  \n",
        "  if voronoi:\n",
        "    index_flat.train(y_pred)\n",
        "\n",
        "  index_flat.add(y_pred)\n",
        "  dists, indx = index_flat.search(y_pred_miss, k = 1) \n",
        "  res = (np.sum(y) + np.sum(y[indx])) / (len(y_pred) + len(y_pred_miss))\n",
        "  return res\n",
        "\n",
        "def annoy_impute(y_pred, y_pred_miss, y, trees = 50):\n",
        "  t = AnnoyIndex(1, \"euclidean\") \n",
        "  for i in range(len(y_pred)):\n",
        "    t.add_item(i, y_pred[i]) \n",
        "\n",
        "  t.build(trees)\n",
        "  indx = np.array([t.get_nns_by_vector(i, 1) for i in y_pred_miss])\n",
        "  res = (np.sum(y) + np.sum(y[indx])) / (len(y_pred) + len(y_pred_miss))\n",
        "  return res\n",
        "\n",
        "def n2_impute(y_pred, y_pred_miss, y, trees = 50):\n",
        "  t = HnswIndex(1, \"euclidean\") \n",
        "  for i in y_pred:\n",
        "    t.add_data(i)\n",
        "\n",
        "  t.build(m=5, n_threads=-1)\n",
        "  indx = t.batch_search_by_vectors(y_pred_miss, 1)\n",
        "  res = (np.sum(y) + np.sum(y[indx])) / (len(y_pred) + len(y_pred_miss))\n",
        "  return res\n",
        "\n",
        "def flann_impute(y_pred, y_pred_miss, y):\n",
        "  flann = FLANN()\n",
        "  indx, dists = flann.nn(y_pred, y_pred_miss, 1, \n",
        "                       algorithm=\"kmeans\", branching=32, iterations=7, checks=16)\n",
        "  res = (np.sum(y) + np.sum(y[indx])) / (len(y_pred) + len(y_pred_miss))\n",
        "  return res\n",
        "\n",
        "def scann_impute(y_pred, y_pred_miss, y):\n",
        "  searcher = scann.scann_ops_pybind.builder(y_pred, 1, \"squared_l2\").tree(\n",
        "      num_leaves=1000, num_leaves_to_search=50, training_sample_size=5000).score_ah(\n",
        "          2, anisotropic_quantization_threshold=0.2).reorder(10).build()\n",
        "  nns, indx = searcher.search_batched(y_pred_miss)\n",
        "  res = (np.sum(y) + np.sum(y[indx])) / (len(y_pred) + len(y_pred_miss))\n",
        "  return res\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC1nDkky0xZy"
      },
      "source": [
        "## Simulation studies outline\n",
        "\n",
        "Here, we conduct simulation study based on predictive mean matching. We replicate study from *Yang, S., & Kim, J. K. (2020). Asymptotic theory and inference of predictive mean matching imputation using a superpopulation model framework. Scandinavian Journal of Statistics, 47(3), 839-861.* paper, however we only assume missing data mechanism\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZdPhEJG13m4",
        "outputId": "da682dc6-0fa5-4297-b4cc-dc5214bf134a"
      },
      "source": [
        "np.random.seed(123)\n",
        "N = 50000\n",
        "x1 = np.random.uniform(size = N)\n",
        "x2 = np.random.uniform(size = N)\n",
        "x3 = np.random.uniform(size = N)\n",
        "x4 = np.random.normal(size = N)\n",
        "x5 = np.random.normal(size = N)\n",
        "x6 = np.random.normal(size = N)\n",
        "epsilon = np.random.normal(size=N)\n",
        "\n",
        "### target variables\n",
        "y1 = -1 + x1 + x2 + epsilon\n",
        "y2 = -1.167 + x1 + x2 + (x1 - 0.5)**2 + + (x2 - 0.5)**2 + epsilon\n",
        "y3 = -1.5 + x1 + x2 + x3 + x4 + x5 + x6 + epsilon\n",
        "\n",
        "## response indicator\n",
        "p1 = np.exp(0.2 + x1 + x2) / (1 + np.exp(0.2 + x1 + x2))\n",
        "\n",
        "data = np.column_stack((x1,x2,x3,x4,x5,x6,y1,y2,y3, p1)).astype('float32')\n",
        "\n",
        "## first three rows\n",
        "data[:3]"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.6964692 ,  0.36086547,  0.20932843,  0.47665665,  0.80429375,\n",
              "        -0.9894137 ,  0.42543107,  0.31638962,  0.42629617,  0.77856696],\n",
              "       [ 0.28613934,  0.22535679,  0.2937351 ,  0.6701647 ,  1.2931948 ,\n",
              "         1.033963  ,  0.25331086,  0.20747614,  3.0443685 ,  0.67073166],\n",
              "       [ 0.22685145,  0.50813043,  0.05571789,  0.5033514 ,  1.5591047 ,\n",
              "         0.13504769,  0.36729714,  0.27497336,  2.1205187 ,  0.71808493]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1LemmH54jxh"
      },
      "source": [
        "### "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_4IDfhK23Ea",
        "outputId": "c12c35dd-3921-43de-a04f-7eb269fb7f5c"
      },
      "source": [
        "R = 100\n",
        "sim1_results_ckdtree = np.zeros(shape = (R, 3))\n",
        "sim1_results_faiss = np.zeros(shape = (R, 3))\n",
        "sim1_results_annoy = np.zeros(shape = (R, 3))\n",
        "sim1_results_n2 = np.zeros(shape = (R, 3))\n",
        "#sim1_results_ckdtree_time\n",
        "\n",
        "for r in range(R):\n",
        "  \n",
        "  #if (r % 10 == 0):\n",
        "  print(r)\n",
        "\n",
        "  np.random.seed(r)\n",
        "  response_flag = np.random.binomial(n=1, p = p1, size = N)\n",
        "  data_resp = data[response_flag == 1]\n",
        "  data_noresp = data[response_flag != 1]\n",
        "  \n",
        "  ## predictive mean matching\n",
        "  ## y1\n",
        "  m1_reg_y1 = LinearRegression().fit(data_resp[:,:2], data_resp[:, 6])\n",
        "  m1_resp_y1_predict = m1_reg_y1.predict(data_resp[:,:2]).reshape(-1,1)\n",
        "  m1_noresp_y1_predict = m1_reg_y1.predict(data_noresp[:,:2]).reshape(-1,1)\n",
        "  ## y2\n",
        "  m1_reg_y2 = LinearRegression().fit(data_resp[:,:2], data_resp[:, 7])\n",
        "  m1_resp_y2_predict = m1_reg_y2.predict(data_resp[:,:2]).reshape(-1,1)\n",
        "  m1_noresp_y2_predict = m1_reg_y2.predict(data_noresp[:,:2]).reshape(-1,1)\n",
        "  ## y3\n",
        "  m1_reg_y3 = LinearRegression().fit(data_resp[:,:6], data_resp[:, 8])\n",
        "  m1_resp_y3_predict = m1_reg_y3.predict(data_resp[:,:6]).reshape(-1,1)\n",
        "  m1_noresp_y3_predict = m1_reg_y3.predict(data_noresp[:,:6]).reshape(-1,1)\n",
        "\n",
        "  ## cktree imputation\n",
        "  sim1_results_ckdtree[r, 0] = kdtree_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "  sim1_results_ckdtree[r, 1] = kdtree_impute(m1_resp_y2_predict, m1_noresp_y2_predict, data_resp[:, 7])\n",
        "  sim1_results_ckdtree[r, 2] = kdtree_impute(m1_resp_y3_predict, m1_noresp_y3_predict, data_resp[:, 8])\n",
        "  \n",
        "  ## faiss imputation\n",
        "  sim1_results_faiss[r, 0] = faiss_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "  sim1_results_faiss[r, 1] = faiss_impute(m1_resp_y2_predict, m1_noresp_y2_predict, data_resp[:, 7])\n",
        "  sim1_results_faiss[r, 2] = faiss_impute(m1_resp_y3_predict, m1_noresp_y3_predict, data_resp[:, 8])\n",
        "\n",
        "  ## annoy imputation\n",
        "  sim1_results_annoy[r, 0] = annoy_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "  sim1_results_annoy[r, 1] = annoy_impute(m1_resp_y2_predict, m1_noresp_y2_predict, data_resp[:, 7])\n",
        "  sim1_results_annoy[r, 2] = annoy_impute(m1_resp_y3_predict, m1_noresp_y3_predict, data_resp[:, 8])\n",
        "\n",
        "  ## annoy imputation\n",
        "  sim1_results_n2[r, 0] = n2_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "  sim1_results_n2[r, 1] = n2_impute(m1_resp_y2_predict, m1_noresp_y2_predict, data_resp[:, 7])\n",
        "  sim1_results_n2[r, 2] = n2_impute(m1_resp_y3_predict, m1_noresp_y3_predict, data_resp[:, 8])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtzLPbxDQxaH"
      },
      "source": [
        ""
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gis7O3A9IXry",
        "outputId": "197eef13-ee23-4cba-e074-7dd144bfa1df"
      },
      "source": [
        "[abs(np.mean(sim1_results_ckdtree, axis = 0) - np.mean(data[:,[6,7,8]], axis = 0)) / np.mean(data[:,[6,7,8]], axis = 0),\n",
        " abs(np.mean(sim1_results_faiss, axis = 0) - np.mean(data[:,[6,7,8]], axis = 0)) / np.mean(data[:,[6,7,8]], axis = 0),\n",
        " abs(np.mean(sim1_results_annoy, axis = 0) - np.mean(data[:,[6,7,8]], axis = 0)) / np.mean(data[:,[6,7,8]], axis = 0),\n",
        " abs(np.mean(sim1_results_n2, axis = 0) - np.mean(data[:,[6,7,8]], axis = 0)) / np.mean(data[:,[6,7,8]], axis = 0)]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-0.19322946,  0.22961392,  0.0252164 ]),\n",
              " array([-0.79157883,  2.55539832, -0.00332338])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OA77tiNPTfqm"
      },
      "source": [
        "flann_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYMasJK6TuZT"
      },
      "source": [
        "scann_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}