{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ann-paper-simulation-1-properties.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BaOylZ_wyYzY"
      ],
      "authorship_tag": "ABX9TyM0GMIvlJ+TU/9jZ7P2Lg3k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DepartmentOfStatisticsPUE/ann-for-survey-sampling/blob/main/ann_paper_simulation_1_properties.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaOylZ_wyYzY"
      },
      "source": [
        "## About\n",
        "\n",
        "This notebook covers simulation study to assess the performance of predictive mean imputation based on exact and approximate nearest neigbours. \n",
        "\n",
        "**Warning**: before runing this scripts go to `Runtime` -> `Change runtime type` and set it to `GPU`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAJ8fCEMyxzQ"
      },
      "source": [
        "## Install requested modules\n",
        "\n",
        "Please note that this may take some time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIGVVBPyyPUw"
      },
      "source": [
        "!apt install libomp-dev\n",
        "!pip install faiss-gpu\n",
        "!pip install n2\n",
        "!pip install scann\n",
        "!pip install annoy ## takes minutes to add data and index\n",
        "!pip install pyflann-py3\n",
        "## !pip install pynndescent -- not suitable for PMM 1d dimension: gets error \"no suitable hyperplains were found\"\n",
        "\n",
        "## this line cleanes information about installing\n",
        "## comment these lines if you want to see the progress \n",
        "from IPython.display import clear_output \n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pMhr7DWznfJ"
      },
      "source": [
        "## Import requested modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYX-DeZRzqzU"
      },
      "source": [
        "## standard modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "## linear regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "## ann modules\n",
        "import scann\n",
        "import faiss\n",
        "from pyflann import *\n",
        "from annoy import AnnoyIndex\n",
        "from n2 import HnswIndex\n",
        "from scipy.spatial import cKDTree\n",
        "from pynndescent import NNDescent\n",
        "\n",
        "## serialization\n",
        "import pickle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkdqmjIT195F"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHUQPEzS1_a3"
      },
      "source": [
        "def kdtree_impute(y_pred, y_pred_miss, y, eps = 0):\n",
        "  tree = cKDTree(y_pred, leafsize = 100, balanced_tree=True)\n",
        "  dists, indx = tree.query(y_pred_miss, k = 1, eps = eps)\n",
        "  res = (np.sum(y) + np.sum(y[indx])) / (len(y_pred) + len(y_pred_miss))\n",
        "  return res\n",
        "\n",
        "def faiss_impute(y_pred, y_pred_miss, y, gpu = True, voronoi = False):\n",
        "  index_flat = faiss.IndexFlatL2(1)\n",
        "\n",
        "  if voronoi:\n",
        "    index_flat = faiss.IndexIVFFlat(index_flat, 1, 1000)\n",
        "\n",
        "  if gpu:\n",
        "    gpu_faiss = faiss.StandardGpuResources() \n",
        "    index_flat = faiss.index_cpu_to_gpu(gpu_faiss, 0, index_flat)\n",
        "  \n",
        "  if voronoi:\n",
        "    index_flat.train(y_pred)\n",
        "\n",
        "  index_flat.add(y_pred)\n",
        "  dists, indx = index_flat.search(y_pred_miss, k = 1) \n",
        "  res = (np.sum(y) + np.sum(y[indx])) / (len(y_pred) + len(y_pred_miss))\n",
        "  return res\n",
        "\n",
        "def annoy_impute(y_pred, y_pred_miss, y, trees = 50):\n",
        "  t = AnnoyIndex(1, \"euclidean\") \n",
        "  for i in range(len(y_pred)):\n",
        "    t.add_item(i, y_pred[i]) \n",
        "\n",
        "  t.build(trees)\n",
        "  indx = np.array([t.get_nns_by_vector(i, 1) for i in y_pred_miss])\n",
        "  res = (np.sum(y) + np.sum(y[indx])) / (len(y_pred) + len(y_pred_miss))\n",
        "  return res\n",
        "\n",
        "def n2_impute(y_pred, y_pred_miss, y, trees = 50):\n",
        "  t = HnswIndex(1, \"euclidean\") \n",
        "  for i in y_pred:\n",
        "    t.add_data(i)\n",
        "\n",
        "  t.build(m=5, n_threads=-1)\n",
        "  indx = t.batch_search_by_vectors(y_pred_miss, 1)\n",
        "  res = (np.sum(y) + np.sum(y[indx])) / (len(y_pred) + len(y_pred_miss))\n",
        "  return res\n",
        "\n",
        "def flann_impute(y_pred, y_pred_miss, y, eps = 0):\n",
        "  flann = FLANN()\n",
        "  indx, dists = flann.nn(y_pred, y_pred_miss, 1, \n",
        "                         algorithm=\"kmeans\", branching=32, iterations=7, \n",
        "                         checks=16, random_seed = 1, eps = eps)\n",
        "  res = (np.sum(y) + np.sum(y[indx])) / (len(y_pred) + len(y_pred_miss))\n",
        "  return res\n",
        "\n",
        "def scann_impute(y_pred, y_pred_miss, y):\n",
        "  searcher = scann.scann_ops_pybind.builder(y_pred, 1, \"squared_l2\").tree(\n",
        "      num_leaves=1000, num_leaves_to_search=50, training_sample_size=5000).score_ah(\n",
        "          2, anisotropic_quantization_threshold=0.2).reorder(10).build()\n",
        "  indx, nns = searcher.search_batched(y_pred_miss)\n",
        "  res = (np.sum(y) + np.sum(y[indx])) / (len(y_pred) + len(y_pred_miss))\n",
        "  return res\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC1nDkky0xZy"
      },
      "source": [
        "## Simulation studies outline\n",
        "\n",
        "Here, we conduct simulation study based on predictive mean matching. We replicate study from *Yang, S., & Kim, J. K. (2020). Asymptotic theory and inference of predictive mean matching imputation using a superpopulation model framework. Scandinavian Journal of Statistics, 47(3), 839-861.* paper, however we only assume missing data mechanism\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZdPhEJG13m4",
        "outputId": "9dd6bc85-57d2-41ed-dbb2-d24d4c87ab9e"
      },
      "source": [
        "np.random.seed(123)\n",
        "N = 50000\n",
        "x1 = np.random.uniform(size = N)\n",
        "x2 = np.random.uniform(size = N)\n",
        "x3 = np.random.uniform(size = N)\n",
        "x4 = np.random.normal(size = N)\n",
        "x5 = np.random.normal(size = N)\n",
        "x6 = np.random.normal(size = N)\n",
        "epsilon = np.random.normal(size=N)\n",
        "\n",
        "### target variables\n",
        "y1 = -1 + x1 + x2 + epsilon\n",
        "y2 = -1.167 + x1 + x2 + (x1 - 0.5)**2 + + (x2 - 0.5)**2 + epsilon\n",
        "y3 = -1.5 + x1 + x2 + x3 + x4 + x5 + x6 + epsilon\n",
        "\n",
        "## response indicator\n",
        "p1 = np.exp(0.2 + x1 + x2) / (1 + np.exp(0.2 + x1 + x2))\n",
        "\n",
        "data = np.column_stack((x1,x2,x3,x4,x5,x6,y1,y2,y3, p1)).astype('float32')\n",
        "\n",
        "## first three rows\n",
        "data[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.6964692 ,  0.36086547,  0.20932843,  0.47665665,  0.80429375,\n",
              "        -0.9894137 ,  0.42543107,  0.31638962,  0.42629617,  0.77856696],\n",
              "       [ 0.28613934,  0.22535679,  0.2937351 ,  0.6701647 ,  1.2931948 ,\n",
              "         1.033963  ,  0.25331086,  0.20747614,  3.0443685 ,  0.67073166],\n",
              "       [ 0.22685145,  0.50813043,  0.05571789,  0.5033514 ,  1.5591047 ,\n",
              "         0.13504769,  0.36729714,  0.27497336,  2.1205187 ,  0.71808493]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1LemmH54jxh"
      },
      "source": [
        "## Simulation study\n",
        "\n",
        "Note, that this simulation may take several hours and you need to be connected to the Interent.\n",
        "\n",
        "Results are stored in a `pickle` format that is naive for `python`'s `DataFrame`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_4IDfhK23Ea",
        "outputId": "0a2d27b4-985b-45bb-a9f6-c7190358e83e"
      },
      "source": [
        "R = 500\n",
        "sim1_results_ckdtree = np.zeros(shape = (R, 3))\n",
        "sim1_results_faiss = np.zeros(shape = (R, 3))\n",
        "sim1_results_faiss_v = np.zeros(shape = (R, 3))\n",
        "sim1_results_annoy = np.zeros(shape = (R, 3))\n",
        "sim1_results_n2 = np.zeros(shape = (R, 3))\n",
        "sim1_results_flann = np.zeros(shape = (R, 3))\n",
        "sim1_results_scann = np.zeros(shape = (R, 3))\n",
        "\n",
        "for r in range(R):\n",
        "  \n",
        "  if (r % 10 == 0):\n",
        "    print(r)\n",
        "\n",
        "  np.random.seed(r)\n",
        "  response_flag = np.random.binomial(n=1, p = p1, size = N)\n",
        "  data_resp = data[response_flag == 1]\n",
        "  data_noresp = data[response_flag != 1]\n",
        "  \n",
        "  ## predictive mean matching\n",
        "  ## y1\n",
        "  m1_reg_y1 = LinearRegression().fit(data_resp[:,:2], data_resp[:, 6])\n",
        "  m1_resp_y1_predict = m1_reg_y1.predict(data_resp[:,:2]).reshape(-1,1)\n",
        "  m1_noresp_y1_predict = m1_reg_y1.predict(data_noresp[:,:2]).reshape(-1,1)\n",
        "  ## y2\n",
        "  m1_reg_y2 = LinearRegression().fit(data_resp[:,:2], data_resp[:, 7])\n",
        "  m1_resp_y2_predict = m1_reg_y2.predict(data_resp[:,:2]).reshape(-1,1)\n",
        "  m1_noresp_y2_predict = m1_reg_y2.predict(data_noresp[:,:2]).reshape(-1,1)\n",
        "  ## y3\n",
        "  m1_reg_y3 = LinearRegression().fit(data_resp[:,:6], data_resp[:, 8])\n",
        "  m1_resp_y3_predict = m1_reg_y3.predict(data_resp[:,:6]).reshape(-1,1)\n",
        "  m1_noresp_y3_predict = m1_reg_y3.predict(data_noresp[:,:6]).reshape(-1,1)\n",
        "\n",
        "  ## cktree imputation\n",
        "  sim1_results_ckdtree[r, 0] = kdtree_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "  sim1_results_ckdtree[r, 1] = kdtree_impute(m1_resp_y2_predict, m1_noresp_y2_predict, data_resp[:, 7])\n",
        "  sim1_results_ckdtree[r, 2] = kdtree_impute(m1_resp_y3_predict, m1_noresp_y3_predict, data_resp[:, 8])\n",
        "  \n",
        "  ## faiss imputation\n",
        "  sim1_results_faiss[r, 0] = faiss_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "  sim1_results_faiss[r, 1] = faiss_impute(m1_resp_y2_predict, m1_noresp_y2_predict, data_resp[:, 7])\n",
        "  sim1_results_faiss[r, 2] = faiss_impute(m1_resp_y3_predict, m1_noresp_y3_predict, data_resp[:, 8])\n",
        "\n",
        "  ## faiss imputation using voronoi\n",
        "  sim1_results_faiss_v[r, 0] = faiss_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6],voronoi = True) \n",
        "  sim1_results_faiss_v[r, 1] = faiss_impute(m1_resp_y2_predict, m1_noresp_y2_predict, data_resp[:, 7],voronoi = True)\n",
        "  sim1_results_faiss_v[r, 2] = faiss_impute(m1_resp_y3_predict, m1_noresp_y3_predict, data_resp[:, 8],voronoi = True)\n",
        "\n",
        "  ## annoy imputation\n",
        "  sim1_results_annoy[r, 0] = annoy_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "  sim1_results_annoy[r, 1] = annoy_impute(m1_resp_y2_predict, m1_noresp_y2_predict, data_resp[:, 7])\n",
        "  sim1_results_annoy[r, 2] = annoy_impute(m1_resp_y3_predict, m1_noresp_y3_predict, data_resp[:, 8])\n",
        "\n",
        "  ## n2 imputation\n",
        "  sim1_results_n2[r, 0] = n2_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "  sim1_results_n2[r, 1] = n2_impute(m1_resp_y2_predict, m1_noresp_y2_predict, data_resp[:, 7])\n",
        "  sim1_results_n2[r, 2] = n2_impute(m1_resp_y3_predict, m1_noresp_y3_predict, data_resp[:, 8])\n",
        "\n",
        "  ## flann imputation\n",
        "  sim1_results_flann[r, 0] = flann_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "  sim1_results_flann[r, 1] = flann_impute(m1_resp_y2_predict, m1_noresp_y2_predict, data_resp[:, 7])\n",
        "  sim1_results_flann[r, 2] = flann_impute(m1_resp_y3_predict, m1_noresp_y3_predict, data_resp[:, 8])\n",
        "\n",
        "  ## scann imputation\n",
        "  sim1_results_scann[r, 0] = scann_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "  sim1_results_scann[r, 1] = scann_impute(m1_resp_y2_predict, m1_noresp_y2_predict, data_resp[:, 7])\n",
        "  sim1_results_scann[r, 2] = scann_impute(m1_resp_y3_predict, m1_noresp_y3_predict, data_resp[:, 8])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "10\n",
            "20\n",
            "30\n",
            "40\n",
            "50\n",
            "60\n",
            "70\n",
            "80\n",
            "90\n",
            "100\n",
            "110\n",
            "120\n",
            "130\n",
            "140\n",
            "150\n",
            "160\n",
            "170\n",
            "180\n",
            "190\n",
            "200\n",
            "210\n",
            "220\n",
            "230\n",
            "240\n",
            "250\n",
            "260\n",
            "270\n",
            "280\n",
            "290\n",
            "300\n",
            "310\n",
            "320\n",
            "330\n",
            "340\n",
            "350\n",
            "360\n",
            "370\n",
            "380\n",
            "390\n",
            "400\n",
            "410\n",
            "420\n",
            "430\n",
            "440\n",
            "450\n",
            "460\n",
            "470\n",
            "480\n",
            "490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gis7O3A9IXry"
      },
      "source": [
        "[abs(np.mean(sim1_results_ckdtree, axis = 0) - np.mean(data[:,[6,7,8]], axis = 0)) / np.mean(data[:,[6,7,8]], axis = 0),\n",
        " abs(np.mean(sim1_results_faiss, axis = 0) - np.mean(data[:,[6,7,8]], axis = 0)) / np.mean(data[:,[6,7,8]], axis = 0),\n",
        " abs(np.mean(sim1_results_faiss_v, axis = 0) - np.mean(data[:,[6,7,8]], axis = 0)) / np.mean(data[:,[6,7,8]], axis = 0),\n",
        " abs(np.mean(sim1_results_annoy, axis = 0) - np.mean(data[:,[6,7,8]], axis = 0)) / np.mean(data[:,[6,7,8]], axis = 0),\n",
        " abs(np.mean(sim1_results_n2, axis = 0) - np.mean(data[:,[6,7,8]], axis = 0)) / np.mean(data[:,[6,7,8]], axis = 0),\n",
        " abs(np.mean(sim1_results_flann, axis = 0) - np.mean(data[:,[6,7,8]], axis = 0)) / np.mean(data[:,[6,7,8]], axis = 0),\n",
        " abs(np.mean(sim1_results_scann, axis = 0) - np.mean(data[:,[6,7,8]], axis = 0)) / np.mean(data[:,[6,7,8]], axis = 0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuylG-z4UvF4"
      },
      "source": [
        "Save results to `dict` object and write to `pkl` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-WfL6v4FWDH"
      },
      "source": [
        "results = {\n",
        "    \"data\": pd.DataFrame(data),\n",
        "    \"sim1_results_ckdtree\" : pd.DataFrame(sim1_results_ckdtree),\n",
        "    \"sim1_results_faiss\" : pd.DataFrame(sim1_results_faiss),\n",
        "    \"sim1_results_faiss_v\" : pd.DataFrame(sim1_results_faiss_v),\n",
        "    \"sim1_results_annoy\": pd.DataFrame(sim1_results_annoy),\n",
        "    \"sim1_results_n2\": pd.DataFrame(sim1_results_n2),\n",
        "    \"sim1_results_flann\" : pd.DataFrame(sim1_results_flann),\n",
        "    \"sim1_results_scann\": pd.DataFrame(sim1_results_scann)\n",
        "          }\n",
        "\n",
        "f = open(\"sim1-results.pkl\",\"wb\")\n",
        "pickle.dump(results,f)\n",
        "f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaYiKC-fkws6"
      },
      "source": [
        "## Processing results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC1Ao7nTky9B",
        "outputId": "5ff37cd6-3ede-4d27-e2f6-9e65f62a2a7c"
      },
      "source": [
        "results = pd.read_pickle(\"sim1-results.pkl\")\n",
        "results.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'sim1_results_ckdtree', 'sim1_results_faiss', 'sim1_results_annoy', 'sim1_results_n2', 'sim1_results_flann', 'sim1_results_faiss_v', 'sim1_results_scann'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgImjQnVk7s1"
      },
      "source": [
        "Calculate bias and standard error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6fxxTx1lBNo",
        "outputId": "0c8cd1bf-fa34-4d0e-cd4f-47cbb48d0a08"
      },
      "source": [
        "ys_true = np.array(np.mean(results[\"data\"].loc[:, [6, 7, 8]], axis = 0))\n",
        "ys_true"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00049869, -0.00018652,  0.01020216], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YY6-Rjo5lcPY",
        "outputId": "3c003a28-270b-4ac9-9f37-a586185d33ec"
      },
      "source": [
        "algos = [\"sim1_results_ckdtree\", \"sim1_results_faiss\", \"sim1_results_faiss_v\",\n",
        "         \"sim1_results_annoy\", \"sim1_results_n2\", \"sim1_results_flann\", \n",
        "         \"sim1_results_scann\"]\n",
        "bias = np.zeros(shape = (len(algos), 3))\n",
        "vars = np.zeros(shape = (len(algos), 3))\n",
        "\n",
        "for i, a in enumerate(algos):\n",
        "  bias[i,:] = np.array(np.mean(results[a], axis = 0)) - ys_true\n",
        "  vars[i,:] = np.array(np.var(results[a], axis = 0))\n",
        "\n",
        "ses = np.sqrt(vars)\n",
        "\n",
        "algos_names = [str(i).replace(\"sim1_results_\", \"\") for i in algos]\n",
        "\n",
        "tab_report = np.column_stack((bias[:, 0], ses[:, 0], bias[:, 1], ses[:, 1], bias[:, 2], ses[:, 2]))\n",
        "\n",
        "print(pd.DataFrame(np.round(tab_report*1000,4), \n",
        "                    index = algos_names, \n",
        "                    columns = [\"bias_y1\", \"se_y1\", \"bias_y2\", \"se_y2\", \"bias_y3\", \"se_y3\"]).to_latex())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\\begin{tabular}{lrrrrrr}\n",
            "\\toprule\n",
            "{} &  bias\\_y1 &    se\\_y1 &  bias\\_y2 &    se\\_y2 &  bias\\_y3 &    se\\_y3 \\\\\n",
            "\\midrule\n",
            "ckdtree &  -0.1764 &   3.4041 &  -0.1932 &   3.9165 &   0.0090 &   3.6757 \\\\\n",
            "faiss   &  -0.5274 &   3.4219 &  -0.5769 &   3.9145 &  -0.0839 &   3.6274 \\\\\n",
            "faiss\\_v &  -0.1765 &   3.4657 &  -0.2439 &   3.9018 &   0.0638 &   3.6788 \\\\\n",
            "annoy   &  -0.1747 &   3.4108 &  -0.1824 &   3.9220 &   0.0078 &   3.6805 \\\\\n",
            "n2      &  -0.1730 &   3.4020 &  -0.1867 &   3.9200 &   0.0101 &   3.6781 \\\\\n",
            "flann   &  -0.1771 &   3.4258 &  -0.1876 &   3.9400 &   0.0280 &   3.6748 \\\\\n",
            "scann   &  -4.4243 &  14.2124 &  -3.3353 &  14.5755 &  -5.6344 &  11.4536 \\\\\n",
            "\\bottomrule\n",
            "\\end{tabular}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEUEyKq7WT8W"
      },
      "source": [
        "# Timings and costs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQvs10e4Y9gw"
      },
      "source": [
        "Timings for N = 50 000 (previously generated)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6mxxQSGWYMr",
        "outputId": "251a48ce-78d8-4006-dcb8-965a5af8247c"
      },
      "source": [
        "%timeit -n 10 kdtree_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6])  \n",
        "%timeit -n 10 faiss_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "%timeit -n 10 faiss_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6], voronoi = True) \n",
        "%timeit -n 10 faiss_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6], gpu = False)\n",
        "%timeit -n 10 annoy_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "%timeit -n 10 n2_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "%timeit -n 10 flann_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "%timeit -n 10 scann_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 43.5 ms per loop\n",
            "10 loops, best of 3: 169 ms per loop\n",
            "10 loops, best of 3: 210 ms per loop\n",
            "10 loops, best of 3: 1.24 s per loop\n",
            "10 loops, best of 3: 4.86 s per loop\n",
            "10 loops, best of 3: 2.74 s per loop\n",
            "10 loops, best of 3: 1.08 s per loop\n",
            "10 loops, best of 3: 664 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rf89J1knZ-0O"
      },
      "source": [
        "Timings for N = 1 000 000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypWXBMJhZ-Oq"
      },
      "source": [
        "np.random.seed(123)\n",
        "N = 1000000\n",
        "x1 = np.random.uniform(size = N)\n",
        "x2 = np.random.uniform(size = N)\n",
        "x3 = np.random.uniform(size = N)\n",
        "x4 = np.random.normal(size = N)\n",
        "x5 = np.random.normal(size = N)\n",
        "x6 = np.random.normal(size = N)\n",
        "epsilon = np.random.normal(size=N)\n",
        "y1 = -1 + x1 + x2 + epsilon\n",
        "y2 = -1.167 + x1 + x2 + (x1 - 0.5)**2 + + (x2 - 0.5)**2 + epsilon\n",
        "y3 = -1.5 + x1 + x2 + x3 + x4 + x5 + x6 + epsilon\n",
        "p1 = np.exp(0.2 + x1 + x2) / (1 + np.exp(0.2 + x1 + x2))\n",
        "data = np.column_stack((x1,x2,x3,x4,x5,x6,y1,y2,y3, p1)).astype('float32')\n",
        "response_flag = np.random.binomial(n=1, p = p1, size = N)\n",
        "data_resp = data[response_flag == 1]\n",
        "data_noresp = data[response_flag != 1]\n",
        "m1_reg_y1 = LinearRegression().fit(data_resp[:,:2], data_resp[:, 6])\n",
        "m1_resp_y1_predict = m1_reg_y1.predict(data_resp[:,:2]).reshape(-1,1)\n",
        "m1_noresp_y1_predict = m1_reg_y1.predict(data_noresp[:,:2]).reshape(-1,1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o_Eq4LmaNp4",
        "outputId": "78664b6e-49ba-4880-8017-251f307f2bd0"
      },
      "source": [
        "%timeit -n 10 kdtree_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6])  \n",
        "%timeit -n 10 faiss_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) \n",
        "%timeit -n 10 scann_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 3.38 s per loop\n",
            "10 loops, best of 3: 10.1 s per loop\n",
            "10 loops, best of 3: 13.9 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq7sfGGRHScl"
      },
      "source": [
        "# Approximate nearest neigbours using KD-TREE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxKWNsfPJJhf",
        "outputId": "df58abd0-a43a-4f78-ae65-ce8a3055868a"
      },
      "source": [
        "np.random.seed(123)\n",
        "N = 250000 ## 50000, 100000, 250000\n",
        "x1 = np.random.uniform(size = N)\n",
        "x2 = np.random.uniform(size = N)\n",
        "x3 = np.random.uniform(size = N)\n",
        "x4 = np.random.normal(size = N)\n",
        "x5 = np.random.normal(size = N)\n",
        "x6 = np.random.normal(size = N)\n",
        "epsilon = np.random.normal(size=N)\n",
        "y1 = -1 + x1 + x2 + epsilon\n",
        "y2 = -1.167 + x1 + x2 + (x1 - 0.5)**2 + + (x2 - 0.5)**2 + epsilon\n",
        "y3 = -1.5 + x1 + x2 + x3 + x4 + x5 + x6 + epsilon\n",
        "p1 = np.exp(0.2 + x1 + x2) / (1 + np.exp(0.2 + x1 + x2))\n",
        "data = np.column_stack((x1,x2,x3,x4,x5,x6,y1,y2,y3, p1)).astype('float32')\n",
        "\n",
        "R = 500\n",
        "sim_ann_naive = np.zeros(shape = (R, 3))\n",
        "sim_ann_kdtree_y1 = np.zeros(shape = (R, 6))\n",
        "sim_ann_kdtree_y2 = np.zeros(shape = (R, 6))\n",
        "sim_ann_kdtree_y3 = np.zeros(shape = (R, 6))\n",
        "\n",
        "for r in range(R):\n",
        "  np.random.seed(r)\n",
        "  print(r)\n",
        "  response_flag = np.random.binomial(n=1, p = p1, size = N)\n",
        "  data_resp = data[response_flag == 1]\n",
        "  data_noresp = data[response_flag != 1]\n",
        "  ## y1\n",
        "  m1_reg_y1 = LinearRegression().fit(data_resp[:,:2], data_resp[:, 6])\n",
        "  m1_resp_y1_predict = m1_reg_y1.predict(data_resp[:,:2]).reshape(-1,1)\n",
        "  m1_noresp_y1_predict = m1_reg_y1.predict(data_noresp[:,:2]).reshape(-1,1)\n",
        "  ## y2\n",
        "  m1_reg_y2 = LinearRegression().fit(data_resp[:,:2], data_resp[:, 7])\n",
        "  m1_resp_y2_predict = m1_reg_y2.predict(data_resp[:,:2]).reshape(-1,1)\n",
        "  m1_noresp_y2_predict = m1_reg_y2.predict(data_noresp[:,:2]).reshape(-1,1)\n",
        "  ## y3\n",
        "  m1_reg_y3 = LinearRegression().fit(data_resp[:,:6], data_resp[:, 8])\n",
        "  m1_resp_y3_predict = m1_reg_y3.predict(data_resp[:,:6]).reshape(-1,1)\n",
        "  m1_noresp_y3_predict = m1_reg_y3.predict(data_noresp[:,:6]).reshape(-1,1)\n",
        "  \n",
        "  sim_ann_naive[r, :] = np.array([np.mean(data_resp[:, 6]), np.mean(data_resp[:, 7]), np.mean(data_resp[:, 8])])\n",
        "  sim_ann_kdtree_y1[r, :] = np.array([kdtree_impute(m1_resp_y1_predict, m1_noresp_y1_predict, data_resp[:, 6], eps = i) for i in [0, 1, 5, 10, 50, 100]])\n",
        "  sim_ann_kdtree_y2[r, :] = np.array([kdtree_impute(m1_resp_y2_predict, m1_noresp_y2_predict, data_resp[:, 7], eps = i) for i in [0, 1, 5, 10, 50, 100]])\n",
        "  sim_ann_kdtree_y3[r, :] = np.array([kdtree_impute(m1_resp_y3_predict, m1_noresp_y3_predict, data_resp[:, 8], eps = i) for i in [0, 1, 5, 10, 50, 100]])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n",
            "215\n",
            "216\n",
            "217\n",
            "218\n",
            "219\n",
            "220\n",
            "221\n",
            "222\n",
            "223\n",
            "224\n",
            "225\n",
            "226\n",
            "227\n",
            "228\n",
            "229\n",
            "230\n",
            "231\n",
            "232\n",
            "233\n",
            "234\n",
            "235\n",
            "236\n",
            "237\n",
            "238\n",
            "239\n",
            "240\n",
            "241\n",
            "242\n",
            "243\n",
            "244\n",
            "245\n",
            "246\n",
            "247\n",
            "248\n",
            "249\n",
            "250\n",
            "251\n",
            "252\n",
            "253\n",
            "254\n",
            "255\n",
            "256\n",
            "257\n",
            "258\n",
            "259\n",
            "260\n",
            "261\n",
            "262\n",
            "263\n",
            "264\n",
            "265\n",
            "266\n",
            "267\n",
            "268\n",
            "269\n",
            "270\n",
            "271\n",
            "272\n",
            "273\n",
            "274\n",
            "275\n",
            "276\n",
            "277\n",
            "278\n",
            "279\n",
            "280\n",
            "281\n",
            "282\n",
            "283\n",
            "284\n",
            "285\n",
            "286\n",
            "287\n",
            "288\n",
            "289\n",
            "290\n",
            "291\n",
            "292\n",
            "293\n",
            "294\n",
            "295\n",
            "296\n",
            "297\n",
            "298\n",
            "299\n",
            "300\n",
            "301\n",
            "302\n",
            "303\n",
            "304\n",
            "305\n",
            "306\n",
            "307\n",
            "308\n",
            "309\n",
            "310\n",
            "311\n",
            "312\n",
            "313\n",
            "314\n",
            "315\n",
            "316\n",
            "317\n",
            "318\n",
            "319\n",
            "320\n",
            "321\n",
            "322\n",
            "323\n",
            "324\n",
            "325\n",
            "326\n",
            "327\n",
            "328\n",
            "329\n",
            "330\n",
            "331\n",
            "332\n",
            "333\n",
            "334\n",
            "335\n",
            "336\n",
            "337\n",
            "338\n",
            "339\n",
            "340\n",
            "341\n",
            "342\n",
            "343\n",
            "344\n",
            "345\n",
            "346\n",
            "347\n",
            "348\n",
            "349\n",
            "350\n",
            "351\n",
            "352\n",
            "353\n",
            "354\n",
            "355\n",
            "356\n",
            "357\n",
            "358\n",
            "359\n",
            "360\n",
            "361\n",
            "362\n",
            "363\n",
            "364\n",
            "365\n",
            "366\n",
            "367\n",
            "368\n",
            "369\n",
            "370\n",
            "371\n",
            "372\n",
            "373\n",
            "374\n",
            "375\n",
            "376\n",
            "377\n",
            "378\n",
            "379\n",
            "380\n",
            "381\n",
            "382\n",
            "383\n",
            "384\n",
            "385\n",
            "386\n",
            "387\n",
            "388\n",
            "389\n",
            "390\n",
            "391\n",
            "392\n",
            "393\n",
            "394\n",
            "395\n",
            "396\n",
            "397\n",
            "398\n",
            "399\n",
            "400\n",
            "401\n",
            "402\n",
            "403\n",
            "404\n",
            "405\n",
            "406\n",
            "407\n",
            "408\n",
            "409\n",
            "410\n",
            "411\n",
            "412\n",
            "413\n",
            "414\n",
            "415\n",
            "416\n",
            "417\n",
            "418\n",
            "419\n",
            "420\n",
            "421\n",
            "422\n",
            "423\n",
            "424\n",
            "425\n",
            "426\n",
            "427\n",
            "428\n",
            "429\n",
            "430\n",
            "431\n",
            "432\n",
            "433\n",
            "434\n",
            "435\n",
            "436\n",
            "437\n",
            "438\n",
            "439\n",
            "440\n",
            "441\n",
            "442\n",
            "443\n",
            "444\n",
            "445\n",
            "446\n",
            "447\n",
            "448\n",
            "449\n",
            "450\n",
            "451\n",
            "452\n",
            "453\n",
            "454\n",
            "455\n",
            "456\n",
            "457\n",
            "458\n",
            "459\n",
            "460\n",
            "461\n",
            "462\n",
            "463\n",
            "464\n",
            "465\n",
            "466\n",
            "467\n",
            "468\n",
            "469\n",
            "470\n",
            "471\n",
            "472\n",
            "473\n",
            "474\n",
            "475\n",
            "476\n",
            "477\n",
            "478\n",
            "479\n",
            "480\n",
            "481\n",
            "482\n",
            "483\n",
            "484\n",
            "485\n",
            "486\n",
            "487\n",
            "488\n",
            "489\n",
            "490\n",
            "491\n",
            "492\n",
            "493\n",
            "494\n",
            "495\n",
            "496\n",
            "497\n",
            "498\n",
            "499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH1so1S9HXc-",
        "outputId": "01dc7d75-1f61-40bd-cc3f-a966616306fa"
      },
      "source": [
        "[abs((np.mean(sim_ann_kdtree_y1, axis = 0) - np.mean(data[:, 6])) / np.mean(data[:, 6]))*100,\n",
        " abs((np.mean(sim_ann_kdtree_y2, axis = 0) - np.mean(data[:, 7])) / np.mean(data[:, 7]))*100,\n",
        " abs((np.mean(sim_ann_kdtree_y3, axis = 0) - np.mean(data[:, 8])) / np.mean(data[:, 8]))*100]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([7.78921202, 7.75129422, 7.90475606, 7.9292983 , 8.06087278,\n",
              "        8.07808074]),\n",
              " array([7.27477802, 7.20647339, 6.92175057, 6.89905654, 6.83946352,\n",
              "        6.82239987]),\n",
              " array([3.78411658, 3.8832197 , 4.12398733, 4.2377823 , 4.26537453,\n",
              "        4.27871993])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLMV9DmwNCCQ",
        "outputId": "ca782ed2-5e93-46c0-cc8d-a501941b9790"
      },
      "source": [
        "[np.sqrt((np.mean(sim_ann_kdtree_y1, axis = 0) - np.mean(data[:, 6]))**2 + np.var(sim_ann_kdtree_y1, axis = 0)),\n",
        " np.sqrt((np.mean(sim_ann_kdtree_y2, axis = 0) - np.mean(data[:, 7]))**2 + np.var(sim_ann_kdtree_y2, axis = 0)),\n",
        " np.sqrt((np.mean(sim_ann_kdtree_y3, axis = 0) - np.mean(data[:, 8]))**2 + np.var(sim_ann_kdtree_y3, axis = 0))]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0.00159192, 0.00159084, 0.00159163, 0.001592  , 0.00159128,\n",
              "        0.00159161]),\n",
              " array([0.00211822, 0.00211887, 0.00212029, 0.00211938, 0.00212058,\n",
              "        0.00212044]),\n",
              " array([0.00155861, 0.00155882, 0.00155797, 0.00155644, 0.00155436,\n",
              "        0.00155453])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kClUmFiTvQ3"
      },
      "source": [
        "results = {\n",
        "    \"data\": pd.DataFrame(data),\n",
        "    \"ann_y1\" : pd.DataFrame(sim_ann_kdtree_y1),\n",
        "    \"ann_y2\" : pd.DataFrame(sim_ann_kdtree_y2),\n",
        "    \"ann_y3\" : pd.DataFrame(sim_ann_kdtree_y3),\n",
        "    \"naive\" : pd.DataFrame(sim_ann_naive)\n",
        "          }\n",
        "\n",
        "f = open(\"sim-ann-kdtree-results-250000.pkl\",\"wb\")\n",
        "pickle.dump(results,f)\n",
        "f.close()"
      ],
      "execution_count": 82,
      "outputs": []
    }
  ]
}